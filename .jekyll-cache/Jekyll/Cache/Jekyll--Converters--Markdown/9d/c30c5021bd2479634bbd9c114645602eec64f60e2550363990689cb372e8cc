I"<p>ì´ë²ˆ ë…¼ë¬¸ì€ Image Representation Learningì—ì„œ SimCLRê³¼ MoCoì˜ ì„±ëŠ¥ì„ ëª¨ë‘ ë›°ì–´ë„˜ì—ˆë‹¤ê³  í•˜ëŠ” BYOL ì…ë‹ˆë‹¤. Google DeepMindì™€ Imperial Collegeì—ì„œ ë°œí‘œí•˜ì˜€ê³ , ê¸°ì¡´ ì—°êµ¬ë“¤ì— ë¹„í•´ Supervised Learning ì„±ëŠ¥(ResNet50, ImageNet acc ê¸°ì¤€)ì— ê°€ì¥ ê·¼ì ‘í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤.</p>

<h2 id="intro">Intro</h2>
<p>Image representation learning ë° Unsupervised learning ë¶„ì•¼ì—ì„œ MoCo, SimCLR ë“±ì´ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆì§€ë§Œ, ì´ëŸ¬í•œ ì„ í–‰ ì—°êµ¬ë“¤ì—ì„  ê³µí†µì ìœ¼ë¡œ, ì ì ˆí•œ augmentationì˜ ì‚¬ìš©ê³¼ í•™ìŠµ ê³¼ì •ì—ì„œ ë§ì€ negative sampleì„ ë³´ëŠ” ê²ƒì´ ì¤‘ìš”í–ˆìŠµë‹ˆë‹¤. ê° ì—°êµ¬ë“¤ì—ì„  ImageNet dataì— ëŒ€í•´ ì‹¤í—˜ì„ í†µí•´ ì ì ˆí•œ Augmentationê³¼ batch sizeë¥¼ ì„¤ì •í–ˆì§€ë§Œ, ì´ ê°’ë“¤ì€ data domainì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆëŠ” ê°’ë“¤ì…ë‹ˆë‹¤. ì¦‰, custom dataì— ì ìš©í•  ê²½ìš°, ëŒ€ëŸ‰ì˜ Unlabeled dataì™€ ì†ŒëŸ‰ì˜ Labeled dataë¥¼ ì‚¬ìš©í•œ Semi-Supervised Learningì„ ì ìš©í•œë‹¤ê³  ìƒê°í•˜ë©´, ì ì ˆí•œ Augmentation ì„ ì •ê³¼ ì‚¬ìš©ê°€ëŠ¥í•œ resource ë‚´ì—ì„œ batch sizeì˜ ì„¤ì • ë“±ì´ ë§ì€ ì‹¤í—˜ì„ í•„ìš”ë¡œ í•  ê²ƒì…ë‹ˆë‹¤.</p>

<p>ì´ ë…¼ë¬¸ì—ì„  ì´ì „ ì—°êµ¬ë“¤ì— ë¹„í•´ batch sizeì™€ augmentationì— ëŒ€í•œ robustnessë¥¼ ì¦ê°€ì‹œí‚¤ë©´ì„œ, Image representation learning ì„±ëŠ¥ë„ ê°œì„ ëœ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. íŠ¹íˆ, í•™ìŠµ ê³¼ì •ì—ì„œ negative sampleì„ ì „í˜€ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ë‹¤ëŠ” ì ì´ ì´ì „ ì—°êµ¬ì™€ëŠ” ê°€ì¥ í° ì°¨ì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‘ ê°œì˜ neural networkì„ ì‚¬ìš©í•˜ê³  ì´ ì¤‘ í•˜ë‚˜ë¥¼ target networkë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ í•µì‹¬ ì•„ì´ë””ì–´ ì…ë‹ˆë‹¤.</p>

<h2 id="methods">Methods</h2>
<p>ë…¼ë¬¸ì˜ motivationì€ ê°„ë‹¨í•œ ì‹¤í—˜ì—ì„œ ì¶œë°œí•©ë‹ˆë‹¤.</p>

<p><img src="/assets/img/post5/motive.jpg" alt="motive" /></p>

<ul>
  <li>step1 : randomly initialized networkë¥¼ freezeí•˜ê³  linear evaluationì„ ì§„í–‰í•©ë‹ˆë‹¤.<br />
-&gt; Acc 1.4%</li>
  <li>step2 : step1ì˜ networkì— MLPë¥¼ ë¶™ì—¬ prediction ê°’ì„ ì–»ìŠµë‹ˆë‹¤.</li>
  <li>step3 : step2ì—ì„œ ì–»ì€ prediction ê°’ì„ targetìœ¼ë¡œ í•˜ì—¬ step1ì²˜ëŸ¼ randomly initialized networkë¥¼ í•™ìŠµí•˜ê³  linear evaluationì„ ì§„í–‰í•©ë‹ˆë‹¤. <br />
-&gt; Acc 18.8%</li>
</ul>

<p>â€œë™ì¼ instanceì— ëŒ€í•´ ë‹¤ë¥¸ augmentationì„ ì ìš©í•œ ì´ë¯¸ì§€ëŠ” representationì´ ë™ì¼í•´ì•¼ í•œë‹¤.â€ ê°€ instance discrimination ë°©ì‹ì¸ contrastive learningì˜ ê¸°ë³¸ ì•„ì´ë””ì–´ ì˜€ëŠ”ë°ìš”. ì´ ì•„ì´ë””ì–´ë§Œìœ¼ë¡œ í•™ìŠµ frameworkì„ êµ¬ì„±í•  ì‹œ, ëª¨ë¸ì€ inputê³¼ ë¬´ê´€í•˜ê²Œ ë™ì¼ representationì„ ì¶œë ¥í•˜ë„ë¡ í•™ìŠµë  ìˆ˜ ìˆê³  ì´ë¥¼ ë…¼ë¬¸ì—ì„œëŠ” â€˜collapsed representationsâ€™ì´ë¼ê³  ë§í•©ë‹ˆë‹¤. ì´ ë¬¸ì œê°€ ì´ì „ ì—°êµ¬ë“¤ì—ì„œ negative sampleì„ ì‚¬ìš©í•´ì•¼ë§Œ í–ˆë˜ ì´ìœ ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
 randomly initialized networkì—ì„œ ì–»ì€ representationì€ ì´ë¯¸ì§€ì˜ íŠ¹ì„±ì„ ì˜ ë°˜ì˜í•œ representationì€ ì•„ë‹ˆê² ì§€ë§Œ</p>

<h2 id="results">Results</h2>

<h2 id="conclusion">Conclusion</h2>

<p>&lt;â€”â€“ ì‘ì„±ì¤‘ â€”â€“&gt;</p>

<h2 id="reference">Reference</h2>
<p>paper :<br />
<a href="https://arxiv.org/abs/2006.07733â€‹">Bootstrap Your Own Latent A New Approach to Self-Supervised Learning</a></p>

<p>etc : <br />
<a href="https://hoya012.github.io/blog/byol/">HOYA012â€™S RESEARCH BLOG : Bootstrap Your Own Latentï¼š A New Approach to Self-Supervised Learning ë¦¬ë·°</a><br />
<a href="https://2-chae.github.io/category/2.papers/26">https://2-chae.github.io/category/2.papers/26</a><br />
<a href="https://cool24151.tistory.com/85">https://cool24151.tistory.com/85</a> 
<a href="https://www.youtube.com/watch?v=BuyWUSPJicM">ë”¥ëŸ¬ë‹ë…¼ë¬¸ì½ê¸°ëª¨ì„ : ì¡°ìš©ë¯¼ - Bootstrap Your Own Latent(BYOL)</a></p>

:ET