I"÷)<p>ì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„  Data Efficient Learning ê´€ë ¨ ì—°êµ¬ ëª‡ ê°€ì§€ë¥¼ ì •ë¦¬í•´ë³´ì•˜ìŠµë‹ˆë‹¤.</p>

<h2 id="prototypical-networks-for-few-shot-learning">Prototypical Networks for Few shot Learning</h2>

<h3 id="overview">Overview</h3>

<p>ê¸°ì¡´ì— í•™ìŠµ ë°ì´í„°ì— ì—†ì—ˆë˜ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ few-shotìœ¼ë¡œ ë¶„ë¥˜í•˜ëŠ” few-shot classification taskë¥¼ ìˆ˜í–‰í•˜ëŠ” ì—°êµ¬ì…ë‹ˆë‹¤. ì´ ë…¼ë¬¸ì—ì„  ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ê¸°ì¡´ í•™ìŠµ ë°ì´í„°ì™€ í•©ì³ì„œ ì²˜ìŒë¶€í„° í•™ìŠµí•˜ëŠ” ë°©ì‹ì´ ì•„ë‹Œ prototypeì„ í™œìš©í•œ metric learning ë°©ì‹ì„ ì œì•ˆí•©ë‹ˆë‹¤.</p>

<p><img src="/assets/img/post10/fig1.png" /></p>

<p>Neural netì„ mapping í•¨ìˆ˜ë¡œ ì‚¬ìš©í•˜ë©° few-shotì˜ ê²½ìš° embedding ê³µê°„ì•ˆì—ì„œ prototype \mathbf{c}_kë¥¼ ê³„ì‚°í•˜ê³  zero-shotì˜ ê²½ìš° ê¸°ì¡´ì— ì¡´ì¬í•˜ëŠ” prototype ì¤‘ ê°€ì¥ ê°€ê¹Œìš´ classë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë°©ì‹ì„ í†µí•´ ë…¼ë¬¸ì—ì„  í•™ìŠµë°ì´í„°ì˜ ì¶”ê°€ ì‹œë‚˜ë¦¬ì˜¤ì— ì§ê´€ì ì´ê³  íš¨ìœ¨ì ì¸ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì„ ì œì•ˆí•˜ì˜€ë‹¤ê³  ë³¼ ìˆ˜ ìˆì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤.</p>

<h3 id="method">Method</h3>

<p>ì œì•ˆëœ MethodëŠ” í¬ê²Œ prototypeì„ ê³„ì‚°í•˜ëŠ” ë¶€ë¶„ê³¼ ê¸°ì¡´ prototypeì„ ì‚¬ìš©í•´ ë¶„ë¥˜í•˜ëŠ” ê³¼ì •ìœ¼ë¡œ ë‚˜ëˆ ì§‘ë‹ˆë‹¤.</p>

<h4 id="prototype-ê³„ì‚°">Prototype ê³„ì‚°</h4>
<p><img src="/assets/img/post10/fig2.png" /></p>

<h4 id="classë³„-probability-ê³„ì‚°">Classë³„ probability ê³„ì‚°</h4>
<p><img src="/assets/img/post10/fig3.png" /></p>

<p>ì•Œê³ ë¦¬ì¦˜ì€ K-means clusteringì˜ centroidë¥¼ ê³„ì‚°í•˜ê³  membershipì„ í• ë‹¹í•˜ëŠ” ê³¼ì •ê³¼ ê±°ì˜ ë˜‘ê°™ì•„ ë³´ì…ë‹ˆë‹¤.
<img src="/assets/img/post10/fig4.png" /></p>

<ol>
  <li>í•™ìŠµ ë°ì´í„° ìƒ˜í”Œë§</li>
  <li>Prototypeì„ ê³„ì‚°í•˜ì—¬ ë¶„ë¥˜ëª¨ë¸ ìƒì„±</li>
  <li>query(í•™ìŠµì— ì¶”ê°€í•  ë°ì´í„°)ì— ëŒ€í•´ ëª¨ë“  prototypeê³¼ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ê³  softmaxë¥¼ ì‚¬ìš©í•´ classification score ê³„ì‚°</li>
  <li>query classification lossë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ í•™ìŠµ</li>
</ol>

<p><img src="/assets/img/post10/fig5.png" /></p>

<h2 id="model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks">Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks</h2>

<h3 id="overview-1">Overview</h3>

<p>MAMLì€ few-shot classificationì„ parameter optimization ê´€ì ìœ¼ë¡œ ì ‘ê·¼í•œ Optimization based meta-learningì˜ ëŒ€í‘œì ì¸ ë…¼ë¬¸ì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

<p><img src="/assets/img/post10/fig6.png" /></p>

<p>ì œì•ˆ ë°©ë²•ì€ ë°ì´í„°ë¥¼ meta-trainsetê³¼ meta-testsetìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ meta-trainìœ¼ë¡œ í•™ìŠµí•œ meta-learnerë¥¼ meta-testsetìœ¼ë¡œ fine tuningí•˜ì˜€ì„ ë•Œì˜ ì„±ëŠ¥ì„ maximizeí•  ìˆ˜ ìˆë„ë¡ meta-learnerë¥¼ í•™ìŠµí•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.</p>

<h3 id="method-1">Method</h3>

<p><img src="/assets/img/post10/fig7.png" /></p>

<p>ì•Œê³ ë¦¬ì¦˜ì„ ë³´ë©´ while-forì˜ ì´ì¤‘ ë°˜ë³µë¬¸ì´ ì‚¬ìš©ëœ ê²ƒì„ ë³¼ ìˆ˜ ìˆëŠ”ë° ê°ê°ì€ outer loopì™€ inner loop ë˜ëŠ” task-specific í•™ìŠµê³¼ meta knowledgeì˜ í•™ìŠµ ë“±ìœ¼ë¡œ êµ¬ë¶„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì „ì²´ ê³¼ì •ì„ ìš”ì•½í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.</p>

<ol>
  <li>í•™ìŠµ ë°ì´í„° ìƒ˜í”Œë§(meta trainset, meta testset)</li>
  <li>
    <p>Inner optimization
<img src="/assets/img/post10/fig8.png" /></p>
  </li>
  <li>Query(ë˜ëŠ” meta testset)ì— ëŒ€í•œ prediction</li>
  <li>Outer optimization
<img src="/assets/img/post10/fig9.png" /></li>
</ol>

<p><img src="/assets/img/post10/fig10.png" /></p>

<p>ìœ„ ê·¸ë¦¼ì€ referenceì˜ ìœ íŠœë¸Œ ê°•ì˜ìë£Œì— ìˆëŠ” MAMLì— ëŒ€í•œ ë„ì‹ì…ë‹ˆë‹¤. ê·¸ë¦¼ì—ì„œë„ ëª…í™•íˆ ë“œëŸ¬ë‚˜ë“¯, MAMLì˜ í•µì‹¬ì€ task-specificí•œ fine-tuningì„ ì˜í•˜ê¸° ìœ„í•œ meta-training ì•Œê³ ë¦¬ì¦˜ì„ ì œì•ˆí•œ ê²ƒì´ë¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¦„ì—ì„œ model-agnosticì´ë¼ê³  ëª…ëª…í•œ ê²ƒì²˜ëŸ¼ ì–´ëŠ task, modelì—ë‚˜ ì‚¬ìš©ë  ìˆ˜ ìˆë‹¤ëŠ” ì¥ì  ë•Œë¬¸ì— MAMLì€ ì´ í›„ ì—¬ëŸ¬ ì—°êµ¬ë“¤ì—ì„œ í™œìš©ë˜ê³  ìˆì§€ë§Œ, ì´ì¤‘ ë°˜ë³µë¬¸ì„ ì‚¬ìš©í•˜ëŠ” bi-level optimization ê³¼ì •ì€ ë§ì€ ì—°ì‚°ëŸ‰ì„ í•„ìš”ë¡œí•œë‹¤ëŠ” ë‹¨ì ë„ ì¡´ì¬í•©ë‹ˆë‹¤.</p>

<h2 id="cycada-cycle-consistent-adversarial-domain-adaptation">CyCADA: Cycle Consistent Adversarial Domain Adaptation</h2>

<h3 id="overview-2">Overview</h3>
<p><img src="/assets/img/post10/fig11.png" /></p>

<p>CyCADAì—ì„  Image to image translationì„ í†µí•´ domain adaptationì„ ìˆ˜í–‰í–ˆê³ , ì›ë³¸ ì´ë¯¸ì§€ë¥¼ targetì˜ styleë¡œ íš¨ê³¼ì ìœ¼ë¡œ ë³€í™˜í•˜ë©´ì„œ ê¸°ì¡´ taskë¥¼ ì˜ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” Cycle consistent adversarial training ë°©ì‹ì„ ì œì•ˆí•©ë‹ˆë‹¤.</p>

<p><img src="/assets/img/post10/fig12.png" /></p>

<p>ë…¼ë¬¸ì—ì„œ ì‚¬ìš©í•œ Loss ëŠ” í¬ê²Œ 4ê°€ì§€ë¡œ ìœ„ì™€ ê°™ì´ ì´ì „ ë°©ë²•ë¡  ë“¤ì—ì„œ ì œì•ˆë˜ì—ˆë˜ ê²ƒë“¤ì„ ì˜ ì¡°í•©í•˜ì—¬ ì„±ëŠ¥ì„ ë‚¸ ì—°êµ¬ì…ë‹ˆë‹¤.</p>

<h3 id="method-2">Method</h3>
<p><img src="/assets/img/post10/fig13.png" /></p>

<p>ì „ì²´ frameworkì€ ìœ„ì™€ ê°™ê³  ì œì•ˆëœ LossëŠ” Pixel Loss, Feature Loss, Semantic Loss, Cycle Consistentë¡œ 4ê°€ì§€ ì…ë‹ˆë‹¤.</p>
<h4 id="pixel-loss">Pixel Loss</h4>
<p><img src="/assets/img/post10/fig14.png" />
$S, T$ : Source, Target , $X$ : ì´ë¯¸ì§€, $G_{S\rightarrow T}$ : Sourceì—ì„œ Targetìœ¼ë¡œ translationí•˜ëŠ” generator</p>

<p>GAN loss(green) : ì¼ë°˜ì ì¸ GAN lossì²˜ëŸ¼ ìƒì„±(í˜¹ì€ translation)ëœ ì´ë¯¸ì§€ì™€ ì‹¤ì œ(target) ì´ë¯¸ì§€ë¥¼ DiscriminatorëŠ” êµ¬ë¶„í•˜ë„ë¡, GeneratorëŠ” êµ¬ë¶„í•˜ì§€ ëª»í•˜ë„ë¡ í•™ìŠµí•˜ê²Œ í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.</p>

<h4 id="feature-loss">Feature Loss</h4>
<p><img src="/assets/img/post10/fig15.png" /></p>

<p>Gan loss(orange) : ì¼ë°˜ì ì¸ GAN lossë¥¼ feature levelì—ì„œ ìˆ˜í–‰í•©ë‹ˆë‹¤.</p>

<h4 id="semantic-loss">Semantic Loss</h4>
<p><img src="/assets/img/post10/fig16.png" /></p>

<p>Semantic Consistency loss(black) : source ì´ë¯¸ì§€ì™€ sourceë¥¼ translation í•œ í›„ì˜ ì´ë¯¸ì§€ê°€ ë™ì¼í•œ taskë¥¼ ì˜ ìˆ˜í–‰í•˜ë„ë¡ ì¼ì¹˜ ì‹œì¼œì£¼ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. $f_S$ëŠ” taskì— ëŒ€í•´ ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ì´ê³ , freeze ëœ ìƒíƒœì—ì„œ ë‚˜ë¨¸ì§€ê°€ í•™ìŠµë©ë‹ˆë‹¤.</p>

<h4 id="cycle-consistent">Cycle Consistent</h4>
<p><img src="/assets/img/post10/fig17.png" /></p>

<p>Cycle loss(red) : source-target-source ìˆœìœ¼ë¡œ translateí•œ ì´ë¯¸ì§€ê°€ ì˜ ë³µì›ë  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” lossë¡œ CycleGANì—ì„œ ì²˜ìŒ ì œì•ˆë˜ì—ˆìŠµë‹ˆë‹¤. ì´ lossëŠ” targetìœ¼ë¡œ domainì „í™˜ í›„ì—ë„ sourceì˜ contentëŠ” ì˜ ìœ ì§€í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.<br />
ì•„ë˜ ì˜ˆì‹œë¥¼ ë³´ë©´, 3ë²ˆì§¸ ì´ë¯¸ì§€ëŠ” ë³€í™˜ í›„ì—ë„ â€˜3â€™ì´ë¼ëŠ” contentë¥¼ ì˜ ìœ ì§€í–ˆê³ , ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ëŠ” ìˆ«ìê°€ ë‘ ê°œ ì´ìƒ ì¡´ì¬í•´ ê·¸ ì¤‘ í•˜ë‚˜ë¥¼ ìœ ì§€í•œ ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

<p><img src="/assets/img/post10/fig18.png" /></p>

<h2 id="meta-pseudo-labels">Meta Pseudo Labels</h2>

<h3 id="overview-3">Overview</h3>
<p>Meta Pseudo Labelsì€ Semi-supervised settingì—ì„œ Image classification taskì˜ SOTAë¥¼ ë‹¬ì„±í–ˆë˜ ë…¼ë¬¸ìœ¼ë¡œ, Unlabeled dataì— ëŒ€í•´ pseudo labelì„ ì‚¬ìš©í•  ë•Œ meta learning ë°©ì‹ì´ ì‚¬ìš©ë©ë‹ˆë‹¤.</p>

<p><img src="/assets/img/post10/fig19.png" /></p>

<p>Pseudo label(left) : ì‚¬ì „í•™ìŠµëœ ê³ ì •ëœ teacherê°€ pseudo labelì„ ìƒì„±í•˜ê³  studentëª¨ë¸ì´ ì´ë¥¼ targetìœ¼ë¡œ í•™ìŠµí•œë‹¤.</p>

<p>Meta Pseudo label(right) : TeacherëŠ” unlabeled dataë¡œ pseudo labelì„ ìƒì„±í•˜ê³  ì´ë¥¼ targetìœ¼ë¡œ í•™ìŠµí•œ <strong>studentê°€ labeled dataì— ëŒ€í•´ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ë„ë¡ teacherê°€ ë‹¤ì‹œ ì—…ë°ì´íŠ¸</strong> ëœë‹¤.</p>

<p>Labeled dataëŠ” student í•™ìŠµì— ì§ì ‘ì ìœ¼ë¡œ ì‚¬ìš©ë˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ì˜¤ë²„í”¼íŒ… ê²½í–¥ì´ ê¸°ì¡´ë³´ë‹¤ ì ìœ¼ë©° ì œì•ˆë°©ë²•ìœ¼ë¡œ í•™ìŠµ í›„, labeled dataë¥¼ ì‚¬ìš©í•´ fine-tuningí•˜ë©´ ì„±ëŠ¥ í–¥ìƒì´ ì¡°ê¸ˆ ë” ê°€ëŠ¥í•˜ë‹¤ê³  í•©ë‹ˆë‹¤.</p>

<p>MPLì€ Teacherë¥¼ targetìœ¼ë¡œ í•™ìŠµí•œ studentë¡œ ë¶€í„° ë‹¤ì‹œ teacherê°€ í”¼ë“œë°±ì„ ë°›ëŠ” êµ¬ì¡°ì´ê¸° ë•Œë¬¸ì— teacherì˜ í•™ìŠµì—ëŠ” ê·¸ë˜ë””ì–¸íŠ¸ì˜ ê·¸ë˜ë””ì–¸íŠ¸ê°€ ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ëŠ” optimization based meta learning ë°©ì‹ì—ì„œë„ ë¬¸ì œê°€ ë˜ì—ˆë˜ Bi-level optimization problemì„ ì•¼ê¸°í•˜ê³ , ì´ ë¶€ë¶„ì„ ê·¸ëŒ€ë¡œ ë‹¤ ê³„ì‚°í•˜ë©´ ì—°ì‚°ëŸ‰ì´ ë„ˆë¬´ ë§ì•„ì§€ê²Œ ë©ë‹ˆë‹¤. ë…¼ë¬¸ì—ì„  Hard pseudo labelì„ ì‚¬ìš©í•˜ëŠ” ì•½ê°„ì˜ íŠ¸ë¦­ì„ ì‚¬ìš©í•´ ì´ ë¶€ë¶„ì„ ê°„ë‹¨íˆ í•˜ê³  ìˆê³  ì´ì— ëŒ€í•œ ìì„¸í•œ ê³¼ì •ì€ Appendixì— ì„¤ëª…ë˜ì–´ ìˆìŠµë‹ˆë‹¤.</p>

<h3 id="method-3">Method</h3>

<p><img src="/assets/img/post10/fig20.png" /></p>

<p>@@ T : \text{teacher},\,\, S : \text{student},\,\, l : \text{labeled}, \,\, u : \text{unlabeled} @@</p>

<p>objective functionì€ ìœ„ì™€ ê°™ìŠµë‹ˆë‹¤. ê³¼ì •ì€ teacherê°€ ìƒì„±í•œ pseudo labelë¡œ student ëª¨ë¸ì„ ë¨¼ì € í•™ìŠµí•˜ê³ (=$\theta_S^{\mathbf{PL}}(\theta_T)$), ì´ë¥¼ $\theta_T$ì— ëŒ€í•œ í•¨ìˆ˜ë¡œ ìƒê°í•˜ì—¬ labeled dataë¥¼ ì‚¬ìš©í•´ Lossë¥¼ minimizeí•˜ëŠ” ìˆœìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.</p>

<p>ì´ë¥¼ ì¢€ ë” ìì„¸íˆ ë³´ë©´ ì•„ë˜ ì‹ê³¼ ê°™ì´ labeled, unlabeled batchë¥¼ í•˜ë‚˜ì”© ì‚¬ìš©í•´ teacher, studentì˜ updateë¥¼ ë°˜ë³µí•˜ëŠ” í˜•íƒœë¡œ, MAMLì˜ ë°©ì‹ì„ ë”°ë¥´ê³  ìˆìŠµë‹ˆë‹¤.</p>

<p><img src="/assets/img/post10/fig21.png" />
<img src="/assets/img/post10/fig22.png" /></p>

<p>ê·¸ëŸ¼ ì „ì²´ Algorithmì„ ë³´ê² ìŠµë‹ˆë‹¤.
<img src="/assets/img/post10/fig23.png" /></p>
<ul>
  <li>Teacherê°€ ìƒì„±í•œ pseudo labelì„ ì‚¬ìš©í•´ studentë¥¼ updateí•©ë‹ˆë‹¤.</li>
</ul>

<p><img src="/assets/img/post10/fig24.png" /></p>
<ul>
  <li>Teacher í•™ìŠµì„ ìœ„í•´ í•„ìš”í•œ Bi-level optimizationì˜ ê³¼ì •ì€ ìœ„ì™€ ê°™ì´ ì„¸ ê°œì˜ cross-entropy lossì˜ gradient ê³±ì„ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.(ìì„¸í•œ ìœ ë„ê³¼ì •ì€ Appendix ì°¸ì¡°)</li>
</ul>

<p><img src="/assets/img/post10/fig25.png" /></p>
<ul>
  <li>Teacherì˜ í•™ìŠµì—ëŠ” ë‹¤ë¥¸ lossë“¤ë„ ê°™ì´ ì‚¬ìš©ë˜ë©° ë…¼ë¬¸ì—ì„œ ì‚¬ìš©í•œ ê²ƒì€ ìœ„ ë‘ ê°€ì§€ ì…ë‹ˆë‹¤. $g^{(t)}_{T, supervised}$ëŠ” Labeled dataë¥¼ ì§ì ‘ teacher í•™ìŠµì— ì‚¬ìš©í•˜ëŠ” supervised lossë¥¼ ì˜ë¯¸í•˜ê³  $$ RandAugmentë¥¼ ì ìš©í•œ outputì´ non-augmentì™€ ê°™ì•„ì§€ë„ë¡ í•˜ëŠ” UDA(Unsupervised Data Augmentation) lossê°€ ì‚¬ìš©ëœë‹¤.</li>
</ul>

<p><img src="/assets/img/post10/fig26.png" /></p>
<ul>
  <li>ë‹¤ìŒ ê³¼ ê°™ì´ ì „ì²´ gradientë¥¼ í•©ì³ì„œ teacherì˜ parameterë¥¼ updateí•œë‹¤. ìµœì¢… prediction ë° evaluationì—ëŠ” studentë¥¼ ì‚¬ìš©í•œë‹¤.</li>
</ul>

<h2 id="reference">Reference</h2>
<p>paper :<br />
<a href="https://arxiv.org/abs/1703.05175">Prototypical Networks for Few-shot Learning</a>  <br />
<a href="https://arxiv.org/abs/1703.03400">Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks</a><br />
<a href="https://arxiv.org/abs/1711.03213">CyCADA: Cycle Consistent Adversarial Domain Adaptation</a><br />
<a href="https://arxiv.org/abs/2003.10580">Meta Pseudo Labels</a></p>

<p>other :<br />
<a href="https://www.youtube.com/watch?v=GDIT193cdoo&amp;list=PLCNc54m6eBRVqlv07SMzSyMjPDB_lNXMC&amp;index=15">Lecture12 AAA738 SeungryongKim</a></p>

:ET