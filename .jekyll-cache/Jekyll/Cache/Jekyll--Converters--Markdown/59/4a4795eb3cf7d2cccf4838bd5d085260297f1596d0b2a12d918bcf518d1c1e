I"h<p>이 논문은 Facebook AI에서 발표하였고, 이미지 Representation Learning 분야에서 SimCLR과 라이벌 격인 논문입니다. SimCLR처럼 Contrastive Learning을 사용하였으며 momentum encoder를 사용하는 부분이 가장 큰 차이라고 할 수 있을 것 같습니다.</p>

<h2 id="intro">Intro</h2>
<p>NLP에서는 GPT, BERT에서 보여주었듯이 Unsupervised Learning이 탁월한 성과를 보여주었지만, Computer vision 분야에서는 여전히 Supervised Learning으로 pre-trained 된 모델의 성능이 우세했습니다. 하지만 MoCo를 활용하여 representation을 학습한 모델은 segmentation, detection을 포함한 7가지 downstream task에서 ImageNet pretrained 모델 대비 우수한 성능을 보여주었습니다. 최근 이미지 representation 학습에서 뛰어난 성과를 보여준 contrastive learning과 dynamic dictionary를 활용하였다고 하는데, 각각에 대해 자세히 살펴보겠습니다.</p>

<h2 id="methode">Methode</h2>
<p><img src="/assets/img/post4/loss_function.jpg" alt="loss" /></p>
<ul>
  <li><img src="https://latex.codecogs.com/svg.latex?\; L_{q}" /> : query 하나에 대한 loss</li>
  <li><img src="https://latex.codecogs.com/svg.latex?\; \tau" /> : temperature, hyper parameter</li>
</ul>

<p>사용된 loss는 위와 같은 모양입니다.<br />
distanace로는 dot product가 사용되었고, sample 하나 당 1개의 positive sample과는 가깝게, K개의 negative sample과는 멀게하는 InfoNCE가 사용되었습니다.</p>

<p><img src="/assets/img/post4/figure1.jpg" alt="figure1" /></p>

<p>위 그림에서 queue가 dictionary를 의미하며, batch size보다 dictionary size를 크게하는 것이 학습 시 좀 더 많은 negative sample을 볼 수 있게 합니다. input 이미지가 momentum encoder를 통과한 key값이 queue를 구성하게 되는데, 그림의 구조가 batch마다 반복되는 것은 아니고, 한 번 queue에 저장된 key값은 추가되는 key값이 dictionary size를 초과하지 않는 한 유지되는 형태입니다.<br />
학습 과정은 논문의 Algorithm 1을 보면 좀 더 정확히 알 수 있습니다.</p>

<p><img src="/assets/img/post4/Algorithm.jpg" alt="Algorithm" /></p>

<ul>
  <li>#1 : momentum encoder를 encoder로 initialize 합니다.</li>
  <li>#3~4 : augmented 이미지로 query와 key에 해당하는 이미지를 정의합니다. augmentation에는 reisze and crop, color jittering, random horizontal flip, random grayscale conversion이 사용되었습니다.</li>
  <li>#5~7 : #3~4에서 구분된 input이 각각 encoder와 momentum encoder를 통과하고 momentum encoder에 대해서는 gradient가 계산되지 않도록 합니다.(backpropagation 제외)</li>
  <li>#9~12 : positive, negative 각각에 대해 logit을 계산하고 InfoNCE를 계산합니다.</li>
  <li>#13~15 : backpropagation하여 encoder를 update하고 기존에 대한 momentum m을 가지도록 momentum encoder를 재정의 합니다.</li>
  <li>#16~17 queue에 이번 minibatch의 key(feature)를 추가하고 가장 오래된 key값을 제외합니다.</li>
</ul>

<p>논문에선 이 알고리즘이 기존과 어떻게 다른지에 대해서도 아래 그림을 통해 설명하고 있습니다.</p>

<p><img src="/assets/img/post4/moco_thumbs.jpg" alt="thumbs" /></p>

<p>먼저, (a)는 dictionary를 따로 구성하지않고 end-to-end로 학습하는 방법으로 query와 key가 같은 encoder를 통과한다고 생각하면 이전에 리뷰했던 SimCLR 형태와 같습니다. 이 경우 negative sample을 많이 보기 위해선 batch size를 크게 해야 하는데요. 실제로 SimCLR에서는 batch size를 8192까지 사용했습니다.(default 는 4192였습니다.)<br />
(b)는 이미지의 key값을 미리 memory bank에 저장해두는 방식입니다. batch size를 크게 하지 않아도 memory bank에 저장된 많은 negative sample의 key값을 사용할 수 있다는 장점이 있는 반면, encoder가 업데이트 됨에 따라 미리 저장된 key값이 consistent하지 않다는 문제가 있습니다.<br />
(a), (b)의 문제들을 모두 해결한 방식이 (c)</p>

<h2 id="results">Results</h2>

<h2 id="conclusion">Conclusion</h2>

<p>&lt;———- ToDo ———-&gt;</p>

<h2 id="reference">Reference</h2>
<p>paper :<br />
<a href="https://arxiv.org/abs/1911.05722​">Momentum Contrast for Unsupervised Visual Representation Learning</a><br />
<a href="https://arxiv.org/abs/2003.04297​​">Improved Baselines with Momentum Contrastive Learning</a></p>

<p>etc : <br />
<a href="https://www.youtube.com/watch?v=2Undxq7jlsA&amp;t=383s">PR-260: Momentum Contrast for Unsupervised Visual Representation Learning</a><br />
<a href="https://velog.io/@tobigs-gm1/Self-Supervised-Learning">투빅스 생성모델 세미나 : Self-Supervised Learning</a><br />
<a href="https://cool24151.tistory.com/82">https://cool24151.tistory.com/82</a></p>

:ET