I"…<p>ì´ ë…¼ë¬¸ì€ Google Brainì—ì„œ ë‚¸ ë…¼ë¬¸ìœ¼ë¡œ, Geoffrey Hinton êµìˆ˜ë‹˜ì´ êµì‹ ì €ìë¡œ ì°¸ì—¬í•˜ì‹  ë…¼ë¬¸ì¸ë°ìš”, í•™ìŠµê³¼ì •ì—ì„œ augmentationê³¼ì˜ ì°¨ì´ë¥¼ í•™ìŠµí•˜ëŠ” ê²ƒìœ¼ë¡œ image representation ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒ ì‹œí‚¨ ë…¼ë¬¸ì…ë‹ˆë‹¤.</p>

<h2 id="intro">Intro</h2>
<p>ì´ ë…¼ë¬¸ì—ì„  contrastive self-supervised learningì„ ì œì•ˆí•˜ì˜€ëŠ”ë°, ì´ êµ¬ì¡°ëŠ” ë³µì¡í•˜ì§€ ì•Šìœ¼ë©° ë³„ë„ì˜ memory bankê°€ í•„ìš”í•˜ì§€ ì•Šë‹¤ëŠ” ë°ì—ì„œ ì´ì „ ì—°êµ¬ë“¤ê³¼ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤.
ë…¼ë¬¸ì—ì„œ ì…ì¦í•œ ë°”ëŠ” í¬ê²Œ 3ê°€ì§€ ì…ë‹ˆë‹¤.</p>
<ul>
  <li>data augmentation ì¡°í•©ì´ SimCLR êµ¬ì¡°ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•œë‹¤.</li>
  <li>representationê³¼ contrasitve loss ì‚¬ì´ì˜ non-linear transformationì´ representation ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¨ë‹¤.</li>
  <li>contrastive learningì€ batch sizeì™€ training stepì´ í´ ë•Œ íš¨ê³¼ì ì´ë‹¤.</li>
</ul>

<p>ì´ë¯¸ì§€ì— ëŒ€í•œ representation learningì€ í¬ê²Œ generativeì™€ discriminativeë¡œ ë‚˜ëˆ ì§‘ë‹ˆë‹¤.
generative ì ‘ê·¼ë°©ì‹ì€ ë§ ê·¸ëŒ€ë¡œ ì´ë¯¸ì§€ë¥¼ reproducingí•˜ëŠ” ê³¼ì •ì—ì„œ ìœ ì˜ë¯¸í•œ representationì„ í•™ìŠµí•˜ëŠ” ë°©ì‹ì´ê³ ,
discriminativeëŠ” pretextë¥¼ ì •ì˜í•˜ê³  ì´ì— ë§ëŠ” objective functionì„ ì •ì˜í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.</p>

<p>ì´ ë…¼ë¬¸ì—ì„  discriminative ë°©ë²• ì¤‘ í•˜ë‚˜ì¸ contrastive learningì„ ì‚¬ìš©í•˜ì˜€ê³ , ë‹¤ì–‘í•œ ì‹¤í—˜ì„ í†µí•´ íš¨ìœ¨ì ìœ¼ë¡œ representationì„ í•™ìŠµí•  ìˆ˜ ìˆëŠ” êµ¬ì¡°ë¥¼ ì œì•ˆí•˜ê³  ìˆìŠµë‹ˆë‹¤.</p>

<h2 id="framework">Framework</h2>
<p><img src="/assets/img/post2/algorithm.jpg" alt="algorithm" />
í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ê³¼ contrastive learningì€ ìœ„ ê·¸ë¦¼ìœ¼ë¡œ ëª¨ë‘ ì„¤ëª…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<ul>
  <li><img src="https://latex.codecogs.com/svg.latex?\; \tau" width="15" /> : ì‚¬ìš©ë  augmenationì˜ ì¢…ë¥˜</li>
  <li><img src="https://latex.codecogs.com/svg.latex?\; t, t^{'}" /> : <img src="https://latex.codecogs.com/svg.latex?\; \tau" width="15" />ì—ì„œ random samplingëœ augmentation</li>
  <li><img src="https://latex.codecogs.com/svg.latex?\; \widetilde{x}_i, \widetilde{x}_j" /> : augmenationëœ ì´ë¯¸ì§€</li>
  <li><img src="https://latex.codecogs.com/svg.latex?\; f(\cdot)" /> : resnet50 outputì—ì„œ global average poolingëœ ê°’, 2048-dimension</li>
  <li><img src="https://latex.codecogs.com/svg.latex?\; g(\cdot)" /> : projection headë¡œ ë‘ ì¸µì˜ MLPì™€ activation í•¨ìˆ˜ reluê°€ ì‚¬ìš©ë¨, contrastive lossì™€ representation ì‚¬ì´ì˜ non-linear representationì´ ì ìš©ë˜ì—ˆë‹¤ê³  í•œ ë¶€ë¶„</li>
  <li>ImageNet ILSVRC-2012 dataset ì‚¬ìš©</li>
  <li>Linear evaluation protocolìœ¼ë¡œ evaluation : representationê¹Œì§€ì˜ parameterë¥¼ freezeí•˜ê³  linear layer í•˜ë‚˜ë§Œ ì¶”ê°€í•˜ì—¬ supervised learning, evaluation ì§„í–‰</li>
</ul>

<p>ê·¸ëŸ¼ loss ì‹ì˜ êµ¬ì„±ì„ í•˜ë‚˜ì”© ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.<br />
<img src="/assets/img/post2/loss.jpg" alt="loss" /></p>

<ul>
  <li>similarity : cosine similarity</li>
  <li><img src="https://latex.codecogs.com/svg.latex?\; \tau" /> : temperature scaling parameter</li>
  <li>i, j : ê°™ì€ ì´ë¯¸ì§€ì— ëŒ€í•´ ë‹¤ë¥¸ augmentationì„ ì ìš©í•œ ë‘ ì´ë¯¸ì§€</li>
  <li>N : batch size</li>
</ul>

<p>ì²« ë²ˆì§¸ ì‹ì„ ë³´ë©´ iì™€ jì˜ ìˆœì„œì— ë”°ë¼ lossê°’ì´ ë‹¬ë¼ì§€ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆëŠ”ë°, ì´ ë•Œë¬¸ì— ë‘ ë²ˆì§¸ ì‹ ì²˜ëŸ¼ ìˆœì„œë¥¼ ë°”ê¾¼ ë‘ loss ê°’ì„ ë”í•´ì£¼ê³  ë¶„ëª¨ì— 2ë¥¼ ì¶”ê°€í•´ì£¼ëŠ” í˜•íƒœê°€ ë©ë‹ˆë‹¤.<br />
ì•„ë˜ ê·¸ë¦¼ì„ ë³´ë©´ ìœ„ loss ì‹ì„ ì§ê´€ì ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

<p><img src="/assets/img/post2/loss_example1.jpg" alt="loss_example1" /></p>

<p>ê³ ì–‘ì´ì™€ ì½”ë¼ë¦¬ ì´ë¯¸ì§€ í•˜ë‚˜ì”©ìœ¼ë¡œ êµ¬ì„±ëœ batch_size=2ì˜ batchë¥¼ ê°€ì •í•´ë´…ì‹œë‹¤.<br />
i, jê°€ augmentationëœ ê³ ì–‘ì´ ì´ë¯¸ì§€ë¼ê³  í•˜ë©´ ìœ„ ê·¸ë¦¼ê³¼ ê°™ì´ ë¶„ëª¨ëŠ” iì™€ ë‹¤ë¥¸ ì´ë¯¸ì§€ë“¤ì˜ similarity í•©ì´ ë˜ê³ , ë¶„ìëŠ” iì™€ j ì‚¬ì´ì˜ similarityê°€ ë©ë‹ˆë‹¤.<br />
ì¦‰, ê°™ì€ ì´ë¯¸ì§€ì— ëŒ€í•œ ë‹¤ë¥¸ augmentationì€ positive sample, ë‹¤ë¥¸ ì´ë¯¸ì§€ì— ëŒ€í•œ augmentation ì´ë¯¸ì§€ëŠ” ëª¨ë‘ negative sampleë¡œ ë¶„ë¥˜í•˜ì—¬
positive sampleê³¼ì˜ similarityëŠ” ê°€ê¹ê²Œ, negative sampleê³¼ì˜ similarityëŠ” ë©€ê²Œ í•™ìŠµí•˜ê¸° ìœ„í•œ loss í•¨ìˆ˜ë¡œ ìƒê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

<p><img src="/assets/img/post2/loss_example2.jpg" alt="loss_example2" /></p>

<p>ê·¸ë¦¬ê³  ì „ì²´ batchì— ëŒ€í•œ lossë¥¼ êµ¬í•´ë³´ë©´ ìœ„ ê·¸ë¦¼ê³¼ ê°™ì´ ë¶„ìì—ëŠ” í˜ì–´ ìˆœì„œì— ë”°ë¼ ë‹¤ë¥¸ lossê°’ë“¤ì„ ëª¨ë‘ ë”í•´ì£¼ê³  ë¶„ëª¨ëŠ” batch_size * 2ê°€ ì˜¤ê²Œë©ë‹ˆë‹¤.<br />
ë…¼ë¬¸ì—ì„  batch_sizeë¥¼ 256~8192ê¹Œì§€ ë‹¤ì–‘í•˜ê²Œ ì‹¤í—˜ì„ í•˜ì˜€ë‹¤ê³  í•˜ëŠ”ë°, 8192ê°œì˜ batchë¡œ ê°€ì •í•˜ë©´ ì´ë¯¸ì§€ í•˜ë‚˜ë‹¹ ë¶„ëª¨ì— ë”í•´ì§€ëŠ” negative sampleê³¼ì˜ similarityëŠ” 2*(8192-1) = 16382ê°€ ë©ë‹ˆë‹¤. ì´ë ‡ê²Œ í° batch_sizeë¥¼ ì ìš©í•˜ê¸° ìœ„í•´ TPU coreë¥¼ 32~128ê°œê¹Œì§€ ì‚¬ìš©í–ˆë‹¤ê³  í•˜ëŠ”ë°, Googleì˜ ìì›ë ¥ì„ í™•ì¸í•  ìˆ˜ ìˆëŠ” ë¶€ë¶„ì¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤.</p>

<h2 id="augmentation">Augmentation</h2>
<p>ë…¼ë¬¸ì—ì„œ ì‚¬ìš©í•œ augmentationì€ random crop</p>

<p>&lt;â€”â€”â€”â€”â€”â€”â€”- ì‘ì„±ì¤‘ â€”â€”â€”â€”â€”â€”â€”-&gt;</p>
<h2 id="reference">reference</h2>
<p>paper :<br />
SimCLR : <a href="https://arxiv.org/abs/2002.05709">https://arxiv.org/abs/2002.05709</a></p>

<p>etc :<br />
The Illustrated SimCLR Framework : <a href="https://amitness.com/2020/03/illustrated-simclr/">https://amitness.com/2020/03/illustrated-simclr/</a><br />
PR-231 : <a href="https://www.youtube.com/watch?v=FWhM3juUM6s&amp;t=1s">https://www.youtube.com/watch?v=FWhM3juUM6s&amp;t=1s</a></p>

:ET