I"¥,<p>ì´ ë…¼ë¬¸ì€ Google Brainì—ì„œ ë‚¸ ë…¼ë¬¸ìœ¼ë¡œ, Geoffrey Hinton êµìˆ˜ë‹˜ì´ êµì‹ ì €ìë¡œ ì°¸ì—¬í•˜ì‹  ë…¼ë¬¸ì¸ë°ìš”, í•™ìŠµê³¼ì •ì—ì„œ augmentationê³¼ì˜ ì°¨ì´ë¥¼ í•™ìŠµí•˜ëŠ” ê²ƒìœ¼ë¡œ image representation ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒ ì‹œí‚¨ ë…¼ë¬¸ì…ë‹ˆë‹¤.</p>

<h2 id="intro">Intro</h2>
<p>ì´ ë…¼ë¬¸ì—ì„  contrastive self-supervised learningì„ ì œì•ˆí•˜ì˜€ëŠ”ë°, ì´ êµ¬ì¡°ëŠ” ë³µì¡í•˜ì§€ ì•Šìœ¼ë©° ë³„ë„ì˜ memory bankê°€ í•„ìš”í•˜ì§€ ì•Šë‹¤ëŠ” ë°ì—ì„œ ì´ì „ ì—°êµ¬ë“¤ê³¼ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤.
ë…¼ë¬¸ì—ì„œ ì…ì¦í•œ ë°”ëŠ” í¬ê²Œ 3ê°€ì§€ ì…ë‹ˆë‹¤.</p>
<ul>
  <li>data augmentation ì¡°í•©ì´ SimCLR êµ¬ì¡°ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•œë‹¤.</li>
  <li>representationê³¼ contrasitve loss ì‚¬ì´ì˜ non-linear transformationì´ representation ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¨ë‹¤.</li>
  <li>contrastive learningì€ batch sizeì™€ training stepì´ í´ ë•Œ íš¨ê³¼ì ì´ë‹¤.</li>
</ul>

<p>ì´ë¯¸ì§€ì— ëŒ€í•œ representation learningì€ í¬ê²Œ generativeì™€ discriminativeë¡œ ë‚˜ëˆ ì§‘ë‹ˆë‹¤.
generative ì ‘ê·¼ë°©ì‹ì€ ë§ ê·¸ëŒ€ë¡œ ì´ë¯¸ì§€ë¥¼ reproducingí•˜ëŠ” ê³¼ì •ì—ì„œ ìœ ì˜ë¯¸í•œ representationì„ í•™ìŠµí•˜ëŠ” ë°©ì‹ì´ê³ ,
discriminativeëŠ” pretextë¥¼ ì •ì˜í•˜ê³  ì´ì— ë§ëŠ” objective functionì„ ì •ì˜í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.</p>

<p>ì´ ë…¼ë¬¸ì—ì„  discriminative ë°©ë²• ì¤‘ í•˜ë‚˜ì¸ contrastive learningì„ ì‚¬ìš©í•˜ì˜€ê³ , ë‹¤ì–‘í•œ ì‹¤í—˜ì„ í†µí•´ íš¨ìœ¨ì ìœ¼ë¡œ representationì„ í•™ìŠµí•  ìˆ˜ ìˆëŠ” êµ¬ì¡°ë¥¼ ì œì•ˆí•˜ê³  ìˆìŠµë‹ˆë‹¤.</p>

<h2 id="framework">Framework</h2>
<p><img src="/assets/img/post2/algorithm.jpg" alt="algorithm" />
í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ê³¼ contrastive learningì€ ìœ„ ê·¸ë¦¼ìœ¼ë¡œ ëª¨ë‘ ì„¤ëª…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<ul>
  <li><img src="https://latex.codecogs.com/svg.latex?\; \tau" width="15" /> : ì‚¬ìš©ë  augmenationì˜ ì¢…ë¥˜</li>
  <li><img src="https://latex.codecogs.com/svg.latex?\; t, t^{'}" /> : <img src="https://latex.codecogs.com/svg.latex?\; \tau" width="15" />ì—ì„œ random samplingëœ augmentation</li>
  <li><img src="https://latex.codecogs.com/svg.latex?\; \widetilde{x}_i, \widetilde{x}_j" /> : augmenationëœ ì´ë¯¸ì§€</li>
  <li><img src="https://latex.codecogs.com/svg.latex?\; f(\cdot)" /> : resnet50 outputì—ì„œ global average poolingëœ ê°’, 2048-dimension</li>
  <li><img src="https://latex.codecogs.com/svg.latex?\; g(\cdot)" /> : projection headë¡œ ë‘ ì¸µì˜ MLPì™€ activation í•¨ìˆ˜ reluê°€ ì‚¬ìš©ë¨, contrastive lossì™€ representation ì‚¬ì´ì˜ non-linear representationì´ ì ìš©ë˜ì—ˆë‹¤ê³  í•œ ë¶€ë¶„</li>
  <li>ImageNet ILSVRC-2012 dataset ì‚¬ìš©</li>
  <li>Linear evaluation protocolìœ¼ë¡œ evaluation : representationê¹Œì§€ì˜ parameterë¥¼ freezeí•˜ê³  linear layer í•˜ë‚˜ë§Œ ì¶”ê°€í•˜ì—¬ supervised learning, evaluation ì§„í–‰</li>
</ul>

<p>ê·¸ëŸ¼ loss ì‹ì˜ êµ¬ì„±ì„ í•˜ë‚˜ì”© ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.<br />
<img src="/assets/img/post2/loss.jpg" alt="loss" /></p>

<ul>
  <li>similarity : cosine similarity</li>
  <li><img src="https://latex.codecogs.com/svg.latex?\; \tau" /> : temperature scaling parameter</li>
  <li>i, j : ê°™ì€ ì´ë¯¸ì§€ì— ëŒ€í•´ ë‹¤ë¥¸ augmentationì„ ì ìš©í•œ ë‘ ì´ë¯¸ì§€</li>
  <li>N : batch size</li>
</ul>

<p>ì²« ë²ˆì§¸ ì‹ì„ ë³´ë©´ iì™€ jì˜ ìˆœì„œì— ë”°ë¼ lossê°’ì´ ë‹¬ë¼ì§€ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆëŠ”ë°, ì´ ë•Œë¬¸ì— ë‘ ë²ˆì§¸ ì‹ ì²˜ëŸ¼ ìˆœì„œë¥¼ ë°”ê¾¼ ë‘ loss ê°’ì„ ë”í•´ì£¼ê³  ë¶„ëª¨ì— 2ë¥¼ ì¶”ê°€í•´ì£¼ëŠ” í˜•íƒœê°€ ë©ë‹ˆë‹¤.<br />
ì•„ë˜ ê·¸ë¦¼ì„ ë³´ë©´ ìœ„ loss ì‹ì„ ì§ê´€ì ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

<p><img src="/assets/img/post2/loss_example1.jpg" alt="loss_example1" /></p>

<p>ê³ ì–‘ì´ì™€ ì½”ë¼ë¦¬ ì´ë¯¸ì§€ í•˜ë‚˜ì”©ìœ¼ë¡œ êµ¬ì„±ëœ batch_size=2ì˜ batchë¥¼ ê°€ì •í•´ë´…ì‹œë‹¤.<br />
i, jê°€ augmentationëœ ê³ ì–‘ì´ ì´ë¯¸ì§€ë¼ê³  í•˜ë©´ ìœ„ ê·¸ë¦¼ê³¼ ê°™ì´ ë¶„ëª¨ëŠ” iì™€ ë‹¤ë¥¸ ì´ë¯¸ì§€ë“¤ì˜ similarity í•©ì´ ë˜ê³ , ë¶„ìëŠ” iì™€ j ì‚¬ì´ì˜ similarityê°€ ë©ë‹ˆë‹¤.<br />
ì¦‰, ê°™ì€ ì´ë¯¸ì§€ì— ëŒ€í•œ ë‹¤ë¥¸ augmentationì€ positive sample, ë‹¤ë¥¸ ì´ë¯¸ì§€ì— ëŒ€í•œ augmentation ì´ë¯¸ì§€ëŠ” ëª¨ë‘ negative sampleë¡œ ë¶„ë¥˜í•˜ì—¬
positive sampleê³¼ì˜ similarityëŠ” í¬ê²Œ, negative sampleê³¼ì˜ similarityëŠ” ì‘ê²Œ í•™ìŠµí•˜ê¸° ìœ„í•œ loss í•¨ìˆ˜ë¡œ ìƒê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

<p><img src="/assets/img/post2/loss_example2.jpg" alt="loss_example2" /></p>

<p>ê·¸ë¦¬ê³  ì „ì²´ batchì— ëŒ€í•œ lossë¥¼ êµ¬í•´ë³´ë©´ ìœ„ ê·¸ë¦¼ê³¼ ê°™ì´ ë¶„ìì—ëŠ” í˜ì–´ ìˆœì„œì— ë”°ë¼ ë‹¤ë¥¸ lossê°’ë“¤ì„ ëª¨ë‘ ë”í•´ì£¼ê³  ë¶„ëª¨ëŠ” batch_size * 2ê°€ ì˜¤ê²Œë©ë‹ˆë‹¤.<br />
ë…¼ë¬¸ì—ì„  batch_sizeë¥¼ 256~8192ê¹Œì§€ ë‹¤ì–‘í•˜ê²Œ ì‹¤í—˜ì„ í•˜ì˜€ë‹¤ê³  í•˜ëŠ”ë°, 8192ê°œì˜ batchë¡œ ê°€ì •í•˜ë©´ ì´ë¯¸ì§€ í•˜ë‚˜ë‹¹ ë¶„ëª¨ì— ë”í•´ì§€ëŠ” negative sampleê³¼ì˜ similarityëŠ” 2*(8192-1) = 16382ê°€ ë©ë‹ˆë‹¤. ì´ë ‡ê²Œ í° batch_sizeë¥¼ ì ìš©í•˜ê¸° ìœ„í•´ TPU coreë¥¼ 32~128ê°œê¹Œì§€ ì‚¬ìš©í–ˆë‹¤ê³  í•˜ëŠ”ë°, Googleì˜ ìì›ë ¥ì„ í™•ì¸í•  ìˆ˜ ìˆëŠ” ë¶€ë¶„ì¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤.</p>

<h2 id="augmentation">Augmentation</h2>
<p>ë…¼ë¬¸ì—ì„œ ì‚¬ìš©í•œ augmentation ì¢…ë¥˜ëŠ” random crop(with flip and resize), color distortion, Gaussian blur ì¸ë°ìš”, ì´ëŸ¬í•œ augmentationì„ ì‚¬ìš©í•˜ëŠ” ê²ƒìœ¼ë¡œ
ì´ì „ê¹Œì§€ ì—°êµ¬ë“¤ì—ì„œ ì ìš©í•œ architectureì˜ ë³€í™”ë¥¼ ëŒ€ì²´í–ˆë‹¤ê³  í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ì´ëŸ¬í•œ augmentationì„ ì ìš©í•˜ê¸°ê¹Œì§€ ì‹¤í—˜ì ì¸ ê²°ê³¼ë“¤ì´ ìˆì—ˆëŠ”ë°ìš”.</p>

<p><img src="/assets/img/post2/augmentation_cm.jpg" alt="augmentation_cm" /></p>

<p>ìœ„ matrixëŠ” SimCLR Frameworkë¡œ í•™ìŠµí•˜ê³  Linear evaluation ë°©ì‹ìœ¼ë¡œ evaluationí•œ ê²°ê³¼ì…ë‹ˆë‹¤. ìœ„ì—ì„œ ì„¤ëª…í•œ frameworkì—ì„œ ì„œë¡œ ë‹¤ë¥¸ augmentation ë‘ ê°œë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í–ˆë˜ ê²ƒê³¼ ë‹¬ë¦¬, ì´ ì‹¤í—˜ì—ì„  í•œ ìª½ branchëŠ” ì›ë³¸ ì´ë¯¸ì§€ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³ , ë‹¤ë¥¸ í•œìª½ì˜ branchì—ì„œ ìœ„ matrix ê°ê°ì— í•´ë‹¹í•˜ëŠ” augmentationì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.<br />
í–‰ê³¼ ì—´ì´ ê°™ì€ ë¶€ë¶„ì—ì„  augmentation í•˜ë‚˜ë§Œ ì‚¬ìš©í•œ ê²ƒì´ê³  ë‹¤ë¥¸ ì„±ë¶„ì— ëŒ€í•´ì„  ê·¸ë¦¼ì— ëª…ì‹œí•œëŒ€ë¡œ í–‰, ì—´ ìˆœìœ¼ë¡œ sequentialí•˜ê²Œ ë‘ ê°œì˜ augmentationì„ ëª¨ë‘ ì‚¬ìš©í•œ ê²ƒì…ë‹ˆë‹¤.
ë¬¼ë¡ , ImageNet dataëŠ” ì‚¬ì´ì¦ˆê°€ ì¼ì •í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ì „ì²´ ì´ë¯¸ì§€ì— ëŒ€í•´ì„œ crop, resizeí•˜ëŠ” ê³¼ì •ì´ ì„ í–‰ìœ¼ë¡œ ì ìš©ë©ë‹ˆë‹¤.</p>

<p>matrix ì¤‘ ëˆˆì— ë„ëŠ” ì„±ëŠ¥ì„ ë³´ì¸ augmentation ì¡°í•©ì´ cropê³¼ color ì…ë‹ˆë‹¤.</p>

<p><img src="/assets/img/post2/color_aug.jpg" alt="color_aug" /></p>

<p>ìœ„ íˆìŠ¤í† ê·¸ë¨ì€ ë‹¤ë¥¸ ë‘ ì´ë¯¸ì§€ì— ëŒ€í•œ crop ì´ë¯¸ì§€ì˜ pixel íˆìŠ¤í† ê·¸ë¨ì…ë‹ˆë‹¤.<br />
(a)ê·¸ë˜í”„ë¥¼ ë³´ë©´ ê°™ì€ ì´ë¯¸ì§€ì— ëŒ€í•œ crop ì´ë¯¸ì§€ëŠ” íˆìŠ¤í† ê·¸ë¨ì´ ê±°ì˜ ìœ ì‚¬í•˜ê³ , ì´ëŠ” ì´ëŸ° í”½ì…€ë¶„í¬ë§Œìœ¼ë¡œë„ ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ êµ¬ë¶„í•  ìˆ˜ ìˆë‹¤ëŠ” ì˜ë¯¸ê°€ ë©ë‹ˆë‹¤.
ì¦‰, color distortion ì—†ì´ ë‹¨ìˆœ cropë§Œìœ¼ë¡œëŠ” ìœ ì˜ë¯¸í•œ representationì´ í•™ìŠµë˜ê¸° ì–´ë µê³ , ë‘ ê°€ì§€ë¥¼ ê°™ì´ ì‚¬ìš©í•´ì•¼ representationì´ ì˜ í•™ìŠµë  ìˆ˜ ìˆê²Œ ë˜ëŠ” ê²ƒì…ë‹ˆë‹¤.</p>

<p><img src="/assets/img/post2/color_aug2.jpg" alt="color_aug2" /></p>

<p>ë˜í•œ, contrastive learningì„ ì ìš©í•  ë•, supervised learningê³¼ ë‹¬ë¦¬ augmentationì˜ ê°•ë„ë¥¼ í¬ê²Œ í–ˆì„ ë•Œ ë” íš¨ê³¼ì ì´ì—ˆëŠ”ë°ìš”.<br />
ìœ„ í‘œë¥¼ë³´ë©´ supervised learningì˜ ê²½ìš° color distortionì„ ê°•í•˜ê²Œ ì ìš©í•´ë„ ì„±ëŠ¥í–¥ìƒì´ ì—†ê±°ë‚˜ ì˜¤íˆë ¤ ì„±ëŠ¥ì´ í•˜ë½í–ˆì§€ë§Œ SimCLRì—ì„  AutoAugê°™ì€ ì •êµí•œ ë°©ë²•ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  ë‹¨ìˆœíˆ 
ë‹¨ìˆœíˆ color distortion strengthë¥¼ ë†’ì´ê³  blurë¥¼ ì¶”ê°€í–ˆì„ ë•Œ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.</p>

<h2 id="architecture">Architecture</h2>
<p><img src="/assets/img/post2/result_depth.jpg" alt="result_depth" /></p>
<ul>
  <li>blue : SimCLR modelë¡œ 100 epoch í•™ìŠµ í›„ Linear evaluation</li>
  <li>red : SimCLR modelë¡œ 1000 epoch í•™ìŠµ í›„ Linear evaluation</li>
  <li>grean : Supervised Learning</li>
</ul>

<p>ì´ ê²°ê³¼ê°€ ë…¼ë¬¸ì—ì„œ ì œì‹œí•œ SimCLRì˜ ì „ì²´ì ì¸ ì„±ëŠ¥ì…ë‹ˆë‹¤. <br />
SimCLRì˜ ì„±ëŠ¥ì€ ResNet50x4 ì‚¬ìš© ì‹œ supervised learningìœ¼ë¡œ í•™ìŠµí•œ ResNet50ê³¼ ë¹„ìŠ·í•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤. ì´ ê²°ê³¼ê°€ ì´ì „ sota ëŒ€ë¹„ 7% ì´ìƒ ê°œì„ ëœ ê²ƒì´ë¼ê³  í•©ë‹ˆë‹¤.
ë˜í•œ, ìœ„ ê·¸ë˜í”„ë¥¼ í†µí•´ SimCLRì˜ í•™ìŠµ ì‹œ, ëª¨ë¸ depth&amp;widthë¥¼ í¬ê²Œí•˜ê³  í•™ìŠµì„ ì˜¤ë˜í•  ìˆ˜ë¡ supervised learning ëŒ€ë¹„ ì„±ëŠ¥ í–¥ìƒ í­ì´ í¼ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

<p><img src="/assets/img/post2/result_projection_head.jpg" alt="result_projection_head" /></p>

<p>ìœ„ ê·¸ë˜í”„ëŠ” projection head ë¶€ë¶„ì— ì‚¬ìš©í•œ non-linear transformationì˜ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.<br />
MLP layer í•˜ë‚˜ë§Œ ì‚¬ìš©í•œ Linearê³¼ representationì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•œ None ëŒ€ë¹„ 2ê°œì˜ MLP layerì™€ reluë¥¼ ì‚¬ìš©í•œ non-linear transfomation ì ìš©ì‹œ ì„±ëŠ¥ì´ ê°€ì¥ ì¢‹ì•˜ìŠµë‹ˆë‹¤.</p>

<p><img src="/assets/img/post2/result_projection_head2.jpg" alt="result_projection_head2" /></p>

<p>ê°œì¸ì ìœ¼ë¡  ìœ„ ê²°ê³¼ê°€ ì¢€ í¥ë¯¸ë¡œìš´ ê²°ê³¼ì´ì§€ ì•Šë‚˜ ìƒê°í•©ë‹ˆë‹¤.<br />
ë…¼ë¬¸ì„ ë³´ë©´ì„œ ë“  ì˜ë¬¸ì´, representationì— ì¶”ê°€í•œ transformationì˜ outputìœ¼ë¡œ constrastive lossë¥¼ ê³„ì‚°í•˜ê³  Linear evaluation ì‹œì—ëŠ” representationì„ ì‚¬ìš©í•˜ëŠ” ë¶€ë¶„ì— ìˆì—ˆìŠµë‹ˆë‹¤.
loss ìì²´ëŠ” ê°™ì€ ì´ë¯¸ì§€ì—ì„œ augmentationëœ ì´ë¯¸ì§€ë“¤ì˜ similarityë¥¼ ë†’ê²Œí•˜ëŠ” termì´ê¸°ì— ê²°êµ­, fì™€ gëŠ” ì´ë¯¸ì§€ì˜ ìœ ì˜ë¯¸í•œ representationë¿ ì•„ë‹ˆë¼ ì ìš©ëœ augmentationì— ë‘”ê°í•´ì§€ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµë˜ê²Œ ë  ê²ƒì…ë‹ˆë‹¤. ì—¬ê¸°ì„œ fì˜ outputì„ representationìœ¼ë¡œ ì‚¬ìš©í•œë‹¤ëŠ” ê²ƒì€ ì´ë¯¸ì§€ì˜ ìœ ì˜ë¯¸í•œ representationì€ fì—ì„œ í•™ìŠµë˜ê³ , gëŠ” augmentationìœ¼ë¡œ ì¸í•œ ë³€í™”ë¥¼ ë¬´ì‹œ(?)í•˜ë„ë¡ í•™ìŠµë¨ì„ â€˜ê°€ì •â€™í•˜ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤.<br />
í•˜ì§€ë§Œ, ìœ„ ê²°ê³¼ë¥¼ ë³´ë©´ g(h)ë¥¼ representationìœ¼ë¡œ ì‚¬ìš©í–ˆì„ ë•Œ, ì´ë¯¸ì§€ ë³€í™˜ì— ëŒ€í•œ ì¸ì‹ë¥ ì´ ë–¨ì–´ì¡Œê³  ì´ëŠ” â€˜ê°€ì •â€™ì´ ì–´ëŠì •ë„ ë§ë‹¤ê³  ë³´ì—¬ì§‘ë‹ˆë‹¤.<br />
ì´ ê²°ê³¼ëŠ” ì•„ë§ˆë„, convolution filterë¡œ í•™ìŠµí•œ ì´ë¯¸ì§€ì˜ featureê°€ augmentationëœ ì´ë¯¸ì§€ë¥¼ ë” ì˜ êµ¬ë¶„í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ ìƒê°í•˜ë©´ rotationì— ëŒ€í•´ g(h)ë¥¼ representationìœ¼ë¡œ ì‚¬ìš©í–ˆì„ ë•Œì˜ ì„±ëŠ¥ì´ í˜„ì €íˆ ë–¨ì–´ì§€ëŠ” ê²ƒì´ ì´í•´ê°€ ë˜ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤.</p>

<h2 id="loss-functions-and-batch-size">Loss functions and Batch Size</h2>
<p><img src="/assets/img/post2/result_loss.jpg" alt="result_loss" />
<img src="/assets/img/post2/result_loss2.jpg" alt="result_loss2" /></p>

<h2 id="comparison-with-other-state-of-the-art">Comparison with other State-of-the-art</h2>
<p><img src="/assets/img/post2/result_other_sota.jpg" alt="result_other_sota" /></p>

<h2 id="conclusion">Conclusion</h2>
<ul>
  <li>Simple frameworkë¡œ self-supervised learning, semi-supervised learning, transfer learningì˜ ì„±ëŠ¥ì„ í¬ê²Œ ê°œì„ í•˜ì˜€ë‹¤.</li>
  <li>supervised learningê³¼ëŠ” ë‹¤ë¥¸ augmentationê³¼ non-linear porjection headë¥¼ ì œì•ˆí•˜ì˜€ë‹¤.</li>
  <li>representationì„ í•™ìŠµí•˜ëŠ” ê²ƒìœ¼ë¡œ supervised learning ìˆ˜ì¤€</li>
</ul>

<p>&lt;â€”â€”â€”â€”â€”â€”â€”- ì‘ì„±ì¤‘ â€”â€”â€”â€”â€”â€”â€”-&gt;</p>
<h2 id="reference">reference</h2>
<p>paper :<br />
SimCLR : <a href="https://arxiv.org/abs/2002.05709">https://arxiv.org/abs/2002.05709</a></p>

<p>etc :<br />
The Illustrated SimCLR Framework : <a href="https://amitness.com/2020/03/illustrated-simclr/">https://amitness.com/2020/03/illustrated-simclr/</a><br />
PR-231 : <a href="https://www.youtube.com/watch?v=FWhM3juUM6s&amp;t=1s">https://www.youtube.com/watch?v=FWhM3juUM6s&amp;t=1s</a></p>

:ET