I"<p>Machine Learningì— ëŒ€í•´ ê³µë¶€í•˜ì‹  ë¶„ì´ë¼ë©´ MLì„ Supervised Learning, Unsupervised Learning, Reinforcement Learningìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê·¸ë¦¼ì„ ë‹¤ì–‘í•œ í˜•íƒœë¡œ ë³´ì…¨ìœ¼ë¦¬ë¼ ìƒê°ë©ë‹ˆë‹¤.
ì—¬ê¸°ì„œ Unsupervised Learningì´ë€ Supervised Learningê³¼ëŠ” ë‹¤ë¥´ê²Œ Labelì´ ì—†ëŠ” ë°ì´í„°ë¡œ í•™ìŠµí•˜ëŠ” ë°©ì‹ì„ ë§í•˜ê³ , ëŒ€í‘œì ìœ¼ë¡œ Clustering(ex. K-means)ê³¼ Dimensionality Reduction(ex. PCA)ì´ ìˆëŠ”ë°ìš”.
ì´ëŸ° ë‚´ìš©ì´ Deep Neural Networkë¥¼ í™œìš©í•˜ëŠ” ë”¥ëŸ¬ë‹ì—ì„  ì¢€ ë” í™•ì¥ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br />
ì´ í¬ìŠ¤íŠ¸ì—ì„  ìµœê·¼ í•«í•œ Deep Learningì—ì„œì˜ Unsupervised Learningì´ ê°€ì§€ëŠ” ì˜ë¯¸ì™€ í™œìš© ì˜ì—­ì— ëŒ€í•´ ì •ë¦¬í•´ë³´ì•˜ìŠµë‹ˆë‹¤.</p>

<h2 id="deep-unsupervised-learning">Deep Unsupervised Learning</h2>

<p>ì•ì— Deepì´ ë¶™ì—ˆì§€ë§Œ Labelì´ ì—†ëŠ” ë°ì´í„°ë¡œ í•™ìŠµì„ í•œë‹¤ëŠ” ê°œë… ìì²´ëŠ” ê°™ê³ , í•™ìŠµì„ í•˜ê¸° ìœ„í•œ ëª¨ë¸ Architectureê°€ DNNì´ë¼ëŠ” ì ì—ì„œ K-means, PCA ë“±ê³¼ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤.
Unsupervised Learningìœ¼ë¡œ DNNì„ í•™ìŠµí•˜ëŠ” ë°©ë²•ì€ í¬ê²Œ ë‘ ê°€ì§€ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

<ul>
  <li>Generative model</li>
  <li>Self-supervised Learning</li>
</ul>

<p>ë¨¼ì €, Generative modelì€ ë§ ê·¸ëŒ€ë¡œ GAN, VAE ê°™ì€ ìƒì„±ëª¨ë¸ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ë³¸ ëª©ì  ê·¸ëŒ€ë¡œ Inputì—ëŠ” ì—†ì§€ë§Œ Inputì— ìˆì„ë²•í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ëª©ì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ë„ ìˆê³ , Generative modelì„ í†µí•´ í•™ìŠµí•œ Inputì˜ ìœ ì˜ë¯¸í•œ featureë¥¼ downstream taskì—ì„œ í™œìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. Self-supervised Learningì€ Labelì´ ì—†ëŠ” ëŒ€ì‹  í•™ìŠµì˜ ë°©í–¥ì„ ê²°ì •í•  ë§Œí•œ pretaskë¥¼ ì„¤ì •í•˜ê³  ì´ì— ë§ê²Œ Supervised Learningì„ ì§„í–‰í•˜ëŠ” í˜•íƒœê°€ ë©ë‹ˆë‹¤. ë‘ ê°€ì§€ ë°©ì‹ ëª¨ë‘ Inputì˜ ìœ ì˜ë¯¸í•œ representationì„ í•™ìŠµí•  ìˆ˜ ìˆë‹¤ëŠ” ì ì—ì„œ Unsupervised Learning ì™¸ì—ë„ semi-supervised learning, transfer learning ë“±ì—ë„ í™œìš©ë„ê°€ ë†’ìŠµë‹ˆë‹¤.</p>

<h2 id="why-unsupervised-learning-">Why Unsupervised Learning ?</h2>

<p>ê·¸ëŸ¼, ì™œ Unsupervised Learningì„ ì‚¬ìš©í•´ì•¼ í• ê¹Œìš”?<br />
ì´ í¬ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•˜ê²Œ ëœ ê³„ê¸°ì´ì ê°€ì¥ ë§ì´ ì°¸ê³ í•œ ìë£Œê°€ UC Berkeley ê°•ì˜(Reference ì°¸ì¡°)ì¸ë°ìš”. ì´ ê°•ì˜ì˜ í‘œí˜„ì„ ë¹Œë¦¬ìë©´ í•œ ë¬¸ì¥ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.</p>
<blockquote>
  <p>â€œIdeal Intelligence is all about compression(finding all patterns)â€</p>
</blockquote>

<p>finding all patternsì€ Inputì— ëŒ€í•œ short descriptionì„ ì°¾ëŠ”ë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤. ì´ëŠ” ìœ ì˜ë¯¸í•œ representationì„ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ í†µí•´ í•™ìŠµí•˜ëŠ” ê²ƒìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆê³ , Supervised Learningì˜ ê²½ìš° Inputì„ ì‚¬ëŒì— ì˜í•´ ì£¼ì–´ì§„ Labelì— ë§ê²Œ í•™ìŠµí•˜ê¸°ì— í•„ìš”í•œ representationì´</p>

<p>&lt;â€”â€”â€”â€”â€“ ì‘ì„±ì¤‘ â€”â€”â€”â€”â€“&gt;</p>

<h2 id="reference">Reference</h2>
<p>L1 Introduction â€“ CS294-158-SP20 Deep Unsupervised Learning â€“ UC Berkeley, Spring 2020</p>
<ul>
  <li><a href="https://www.youtube.com/watch?v=V9Roouqfu-M">ìœ íŠœë¸Œ ê°•ì˜</a></li>
  <li><a href="https://sites.google.com/view/berkeley-cs294-158-sp19/home?fbclid=IwAR3EYrnDoHv05sL6Exk77urKYJ3VOs85y1UggUvKbnCBDMygcUHXL0qD-28">ê°•ì˜ìë£Œ</a></li>
</ul>

<p>Title_img : <a href="https://quoracreative.com/article/machine-learning-marketing-Sales">https://quoracreative.com/article/machine-learning-marketing-Sales</a></p>

:ET