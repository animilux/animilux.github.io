I"È<p>ì´ë²ˆ ë…¼ë¬¸ì€ Image Representation Learningì—ì„œ SimCLRê³¼ MoCoì˜ ì„±ëŠ¥ì„ ëª¨ë‘ ë›°ì–´ë„˜ì—ˆë‹¤ê³  í•˜ëŠ” BYOL ì…ë‹ˆë‹¤. Google DeepMindì™€ Imperial Collegeì—ì„œ ë°œí‘œí•˜ì˜€ê³ , ê¸°ì¡´ ì—°êµ¬ë“¤ì— ë¹„í•´ Supervised Learning ì„±ëŠ¥(ResNet50, ImageNet acc ê¸°ì¤€)ì— ê°€ì¥ ê·¼ì ‘í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤.</p>

<h2 id="intro">Intro</h2>
<p>Image representation learning ë° Unsupervised learning ë¶„ì•¼ì—ì„œ MoCo, SimCLR ë“±ì´ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆì§€ë§Œ, ì´ëŸ¬í•œ ì„ í–‰ ì—°êµ¬ë“¤ì—ì„  ê³µí†µì ìœ¼ë¡œ, ì ì ˆí•œ augmentationì˜ ì‚¬ìš©ê³¼ í•™ìŠµ ê³¼ì •ì—ì„œ ë§ì€ negative sampleì„ ë³´ëŠ” ê²ƒì´ ì¤‘ìš”í–ˆìŠµë‹ˆë‹¤. ê° ì—°êµ¬ë“¤ì—ì„  ImageNet dataì— ëŒ€í•´ ì‹¤í—˜ì„ í†µí•´ ì ì ˆí•œ Augmentationê³¼ batch sizeë¥¼ ì„¤ì •í–ˆì§€ë§Œ, ì´ ê°’ë“¤ì€ data domainì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆëŠ” ê°’ë“¤ì…ë‹ˆë‹¤. ì¦‰, custom dataì— ì ìš©í•  ê²½ìš°, ëŒ€ëŸ‰ì˜ Unlabeled dataì™€ ì†ŒëŸ‰ì˜ Labeled dataë¥¼ ì‚¬ìš©í•œ Semi-Supervised Learningì„ ì ìš©í•œë‹¤ê³  ìƒê°í•˜ë©´, ì ì ˆí•œ Augmentation ì„ ì •ê³¼ ì‚¬ìš©ê°€ëŠ¥í•œ resource ë‚´ì—ì„œ batch sizeì˜ ì„¤ì • ë“±ì´ ë§ì€ ì‹¤í—˜ì„ í•„ìš”ë¡œ í•  ê²ƒì…ë‹ˆë‹¤.</p>

<p>ì´ ë…¼ë¬¸ì—ì„  ì´ì „ ì—°êµ¬ë“¤ì— ë¹„í•´ batch sizeì™€ augmentationì— ëŒ€í•œ robustnessë¥¼ ì¦ê°€ì‹œí‚¤ë©´ì„œ, Image representation learning ì„±ëŠ¥ë„ ê°œì„ ëœ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. íŠ¹íˆ, í•™ìŠµ ê³¼ì •ì—ì„œ negative sampleì„ ì „í˜€ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ë‹¤ëŠ” ì ì´ ì´ì „ ì—°êµ¬ì™€ëŠ” ê°€ì¥ í° ì°¨ì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‘ ê°œì˜ neural networkì„ ì‚¬ìš©í•˜ê³  ì´ ì¤‘ í•˜ë‚˜ë¥¼ target networkë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ í•µì‹¬ ì•„ì´ë””ì–´ ì…ë‹ˆë‹¤.</p>

<h2 id="methods">Methods</h2>
<p>ë…¼ë¬¸ì˜ motivationì€ ê°„ë‹¨í•œ ì‹¤í—˜ì—ì„œ ì¶œë°œí•©ë‹ˆë‹¤.</p>

<p><img src="/assets/img/post5/motive.jpg" alt="motive" /></p>

<ul>
  <li>step1 : randomly initialized networkë¥¼ freezeí•˜ê³  linear evaluationì„ ì§„í–‰í•©ë‹ˆë‹¤.<br />
-&gt; Acc 1.4%</li>
  <li>step2 : step1ì˜ networkì— MLPë¥¼ ë¶™ì—¬ prediction ê°’ì„ ì–»ìŠµë‹ˆë‹¤.</li>
  <li>step3 : step2ì—ì„œ ì–»ì€ prediction ê°’ì„ targetìœ¼ë¡œ í•˜ì—¬ step1ì²˜ëŸ¼ randomly initialized networkë¥¼ í•™ìŠµí•˜ê³  linear evaluationì„ ì§„í–‰í•©ë‹ˆë‹¤. <br />
-&gt; Acc 18.8%</li>
</ul>

<p>â€œë™ì¼ instanceì— ëŒ€í•´ ë‹¤ë¥¸ augmentationì„ ì ìš©í•œ ì´ë¯¸ì§€ëŠ” representationì´ ë™ì¼í•´ì•¼ í•œë‹¤.â€ ê°€ instance discrimination ë°©ì‹ì¸ contrastive learningì˜ ê¸°ë³¸ ì•„ì´ë””ì–´ ì˜€ëŠ”ë°ìš”. ì´ ì•„ì´ë””ì–´ë§Œìœ¼ë¡œ í•™ìŠµ frameworkì„ êµ¬ì„±í•  ì‹œ, ëª¨ë¸ì€ inputê³¼ ë¬´ê´€í•˜ê²Œ ë™ì¼ representationì„ ì¶œë ¥í•˜ë„ë¡ í•™ìŠµë  ìˆ˜ ìˆê³  ì´ë¥¼ ë…¼ë¬¸ì—ì„œëŠ” â€˜collapsed representationsâ€™ì´ë¼ê³  ë§í•©ë‹ˆë‹¤. ì´ ë¬¸ì œê°€ ì´ì „ ì—°êµ¬ë“¤ì—ì„œ negative sampleì„ ì‚¬ìš©í•´ì•¼ë§Œ í–ˆë˜ ì´ìœ ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

<p>ì—¬ê¸°ì„œ, í•™ìŠµì„ ì‹œì‘í•˜ê¸°ì „ randomly initialized networkì—ì„œ ì–»ì€ representationì„ ìƒê°í•´ë³´ë©´ ì´ë¯¸ì§€ì˜ íŠ¹ì„±ì„ ì˜ ë°˜ì˜í•œ representationì€ ì•„ë‹ˆê² ì§€ë§Œ, ì•„ì§ í•™ìŠµì„ ì‹œì‘í•˜ì§€ ì•Šì•˜ê¸°ì— collapsed ë¬¸ì œëŠ” ì—†ì„ ê²ƒìœ¼ë¡œ ìƒê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ ì–»ì€ representationì˜ ì„±ëŠ¥ì´ step1ì—ì„œ êµ¬í•œ 1.4%ì˜€ìŠµë‹ˆë‹¤. ImageNet ë°ì´í„°ê°€ 1000ê°œì˜ classì„ì„ ê°ì•ˆí•˜ë©´ í•™ìŠµí•œ 1ê°œì˜ linear layerì—ì„œ ì–´ëŠì •ë„ì˜ í•™ìŠµì€ ì´ë£¨ì–´ì§„ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.</p>

<p>step2~3ì˜ ê²°ê³¼ëŠ” step1ì—ì„œ ì–»ì€ ì˜ë¯¸ì—†ëŠ”(randomly initilized ì´ë¯€ë¡œ) representationì„ targetìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ê²ƒë„ ì–´ëŠ ì •ë„ì˜ ì˜ë¯¸ëŠ” ìˆë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ ë¶€ë¶„ì´ ê°œì¸ì ìœ¼ë¡œ ì¢€ ì‹ ê¸°í•œ ë¶€ë¶„ì´ì—ˆëŠ”ë°ìš”. í‹€ë¦° ë‹µìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ê²ƒë„ ì „í˜€ í•™ìŠµí•˜ì§€ ì•Šì€ ê²ƒë³´ë‹¤ëŠ” ë„ì›€ì´ ëœë‹¤ê³  í•´ì„í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.</p>

<p>ë…¼ë¬¸ì—ì„  ìœ„ ì‹¤í—˜ê²°ê³¼ë¥¼ ì‹œì‘ìœ¼ë¡œ representationì„ í•™ìŠµí•  online networkì™€ í•™ìŠµí•˜ëŠ” predictionì„ ì¶œë ¥í•  target networkë¥¼ ì•„ë˜ì™€ ê°™ì´ ì„¤ê³„í•˜ê²Œ ë©ë‹ˆë‹¤.</p>

<p><img src="/assets/img/post5/byol_thumbs.jpg" alt="byol_thumbs" /></p>

<ul>
  <li><img src="https://latex.codecogs.com/svg.latex?\; v, v' : " height="20" /> augmented image</li>
  <li><img src="https://latex.codecogs.com/svg.latex?\; f_{\theta}, f_{\xi} :" wdith="20" /> randomly initialized network</li>
  <li><img src="https://latex.codecogs.com/svg.latex?\; g_{\theta}, g_{\xi} :" wdith="20" /> projector</li>
  <li><img src="https://latex.codecogs.com/svg.latex?\; q_{\theta} : " height="13" /> predictor</li>
  <li><img src="https://latex.codecogs.com/svg.latex?\; sg(z'_{\xi}) : " height="20" /> stop gradient</li>
</ul>

<p>online, target networkë¥¼ ë‚˜ëˆ ì„œ ì„¤ê³„í–ˆë‹¤ëŠ” ê²ƒ ì™¸ì—ë„ ìœ„ ê·¸ë¦¼ì„ ë³´ë©´ onlineì—ë§Œ predictorê°€ ì¶”ê°€ì ìœ¼ë¡œ ì‚¬ìš©í•œ ê²ƒì´ ë³´ì…ë‹ˆë‹¤. ablation studyì˜ ê²°ê³¼ë¡œ 
<img src="https://latex.codecogs.com/svg.latex?\; y_{\theta} : " height="15" /> representation, downstream taskì— ì‚¬ìš©ë¨<br />
<img src="https://latex.codecogs.com/svg.latex?\; \xi \leftarrow \tau \xi + (1-\tau)\theta " height="20" /> : ë§¤ epoch ë§ˆë‹¤ target network update</p>

<h2 id="results">Results</h2>

<h2 id="conclusion">Conclusion</h2>

<p>&lt;â€”â€“ ì‘ì„±ì¤‘ â€”â€“&gt;</p>

<h2 id="reference">Reference</h2>
<p>paper :<br />
<a href="https://arxiv.org/abs/2006.07733â€‹">Bootstrap Your Own Latent A New Approach to Self-Supervised Learning</a></p>

<p>etc : <br />
<a href="https://hoya012.github.io/blog/byol/">HOYA012â€™S RESEARCH BLOG : Bootstrap Your Own Latentï¼š A New Approach to Self-Supervised Learning ë¦¬ë·°</a><br />
<a href="https://2-chae.github.io/category/2.papers/26">https://2-chae.github.io/category/2.papers/26</a><br />
<a href="https://cool24151.tistory.com/85">https://cool24151.tistory.com/85</a> 
<a href="https://www.youtube.com/watch?v=BuyWUSPJicM">ë”¥ëŸ¬ë‹ë…¼ë¬¸ì½ê¸°ëª¨ì„ : ì¡°ìš©ë¯¼ - Bootstrap Your Own Latent(BYOL)</a></p>

:ET