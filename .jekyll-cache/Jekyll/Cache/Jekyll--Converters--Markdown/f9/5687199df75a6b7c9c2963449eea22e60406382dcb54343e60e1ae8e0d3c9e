I"W<p>ì´ë²ˆ ë…¼ë¬¸ì€ ê·¸ë™ì•ˆ ë¦¬ë·°í–ˆë˜ Image Representation Learningì„ ì‚¬ìš©í•˜ì—¬ downstream taskë¡œ clusteringì„ ì§„í–‰í•œ SCAN(Semantic Clustering by Adopting Nearest neighbors)ì´ë¼ëŠ” ë…¼ë¬¸ì…ë‹ˆë‹¤.
Unsupervised Image classification ì´ë¼ëŠ” í”ì¹˜ì•Šì€(?) taskë¥¼ ìˆ˜í–‰í–ˆë‹¤ê³  í•©ë‹ˆë‹¤.</p>

<h2 id="intro">Intro</h2>
<ul>
  <li>Unsupervised Image Classification</li>
  <li>Two-step approach(not end-to-end)</li>
  <li>First : â€œSelf-supervised task from representation learning is employed to obtain semantically meaningful features.â€</li>
  <li>Second : â€œWe use the obtained features as a prior in a learnable clustering approach.â€</li>
</ul>

<p>ìœ„ ë„¤ ê°€ì§€ë¡œ ë…¼ë¬¸ì„ ìš”ì•½í•  ìˆ˜ ìˆì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤. Unsupervised Image Classificationì„ ìˆ˜í–‰í•˜ì˜€ê³ , ì´ ê³¼ì •ì„ Representation Learning, clusteringìœ¼ë¡œ ë‚˜ëˆ„ì–´ êµ¬ì„±í•˜ì˜€ìŠµë‹ˆë‹¤. ë…¼ë¬¸ì˜ Experiment ë¶€ë¶„ì„ ë´¤ì„ ë•Œ, Unsupervised Image Classificationì€ evaluationì—ì„œ í—ê°€ë¦¬ì•ˆ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•œë‹¤ëŠ” ì ì—ì„œ ë‹¨ìˆœ Clusteringê³¼ êµ¬ë¶„ëœ í‘œí˜„ì¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤.</p>

<h2 id="prior-work">Prior work</h2>
<h3 id="feature-learning-with-clustering">Feature Learning with clustering</h3>

<p><img src="/assets/img/post7/img1.jpg" alt="img1" /></p>

<p>ë…¼ë¬¸ì—ì„œ Deep Clusteringì„ ì£¼ìš” ë¹„êµ ëŒ€ìƒìœ¼ë¡œ ì‚¼ê³  ìˆìŠµë‹ˆë‹¤.</p>

<blockquote>
  <p>â€œThe good performance of random convnets is intimately tied to their convolutional structure which gives a strong prior on the input signal. The idea of this work is to exploit this weak signal to bootstrap the discriminative power of a convnet.â€</p>
</blockquote>

<p>Deep Clusteringì€ ìœ„ì™€ ê°™ì€ ì•„ì´ë””ì–´ë¡œ random initialized CNNì˜ outputì„ clusteringí•œ ê²°ê³¼ë¥¼ supervisionì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì˜ representationì„ í•™ìŠµí•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•˜ì˜€ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ í•™ìŠµë°©ì‹ì€ í•™ìŠµ ì´ˆë°˜ì— ì •í™•í•˜ì§€ ì•Šì€ clustering ê²°ê³¼ë¥¼ supervisionìœ¼ë¡œ ì‚¬ìš©í•œë‹¤ëŠ” ë¬¸ì œë¥¼ ê°€ì§€ê³  ìˆëŠ”ë° SCANì—ì„  ì´ë¥¼ ì§€ì í•˜ë©° ì´ëŸ¬í•œ Clustering degeneracy ë¬¸ì œë¥¼ ê°œì„ í•œ ê²ƒì´ ì£¼ìš” contributionì´ë¼ ë§í•©ë‹ˆë‹¤.</p>

<h2 id="method">Method</h2>
<p>SCANì˜ í•™ìŠµê³¼ì •ì€ í¬ê²Œ Pretext task, Scan Clustering, Self-labelingìœ¼ë¡œ ë‚˜ëˆ ì§‘ë‹ˆë‹¤.</p>
<h3 id="p">P</h3>
<blockquote>
  <p>â€œWe employ representation learning as a means to obtain a better prior for semantic clustering.â€</p>
</blockquote>

<p>ë¨¼ì €, pretext taskëŠ” Image Representation Leanringì˜ ì„ í–‰ ì—°êµ¬ì¸ SimCLR, MOCOë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. Image transformationì— ë”°ë¼ ë³€í•˜ì§€ ì•ŠëŠ” semantic featureë¥¼ í•™ìŠµí•˜ê¸° ë•Œë¬¸ì— ë‘ ë°©ë²•ì„ ì‚¬ìš©í–ˆë‹¤ê³  í•˜ê³ , contrastive learningì— ì‚¬ìš©ëœ instance discrimination ë°©ì‹ì´ ê²°ê³¼ì ìœ¼ë¡œ ê°™ì€ class ê°„ì˜ ê±°ë¦¬ë¥¼ ìƒëŒ€ì ìœ¼ë¡œ ê°€ê¹ê²Œ í•˜ê¸° ë•Œë¬¸ì— ì´ë¥¼ Clusteringì— ì‚¬ìš©í•˜ê¸° ìœ„í•¨ì…ë‹ˆë‹¤.</p>

<p><img src="/assets/img/post7/fig1.jpg" width="700" /></p>

<p>&lt;â€”â€”â€”â€”â€”-ì‘ì„± ì¤‘â€”â€”â€”â€”â€”-&gt;</p>

<h2 id="reference">Reference</h2>
<p>paper :<br />
<a href="https://arxiv.org/abs/2005.12320â€‹">SCAN: Learning to Classify Images without Labels</a> <br />
<a href="https://arxiv.org/abs/1807.05520â€‹">Deep Clustering for Unsupervised Learning of Visual Features</a><br />
<a href="https://arxiv.org/abs/2002.05709">A Simple Framework for Contrastive Learning of Visual Representations</a>  <br />
<a href="https://arxiv.org/abs/1911.05722â€‹">Momentum Contrast for Unsupervised Visual Representation Learning</a>  <br />
<a href="https://arxiv.org/abs/2003.04297â€‹â€‹">Improved Baselines with Momentum Contrastive Learning</a></p>

:ET