I"g<p>ì´ ë…¼ë¬¸ì€ Geoffrey Hinton êµìˆ˜ë‹˜ì´ êµì‹ ì €ìë¡œ ì°¸ì—¬í•˜ì‹  ë…¼ë¬¸ì¸ë°ìš”, í•™ìŠµê³¼ì •ì—ì„œ augmentationê³¼ì˜ ì°¨ì´ë¥¼ í•™ìŠµí•˜ëŠ” ê²ƒìœ¼ë¡œ image representation ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒ ì‹œí‚¨ ë…¼ë¬¸ì…ë‹ˆë‹¤.</p>

<h2 id="intro">Intro</h2>
<p>ì´ ë…¼ë¬¸ì—ì„  contrastive self-supervised learningì„ ì œì•ˆí•˜ì˜€ëŠ”ë°, ì´ êµ¬ì¡°ëŠ” ë³µì¡í•˜ì§€ ì•Šìœ¼ë©° ë³„ë„ì˜ memory bankê°€ í•„ìš”í•˜ì§€ ì•Šë‹¤ëŠ” ë°ì—ì„œ ì´ì „ ì—°êµ¬ë“¤ê³¼ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤.
ë…¼ë¬¸ì—ì„œ ì…ì¦í•œ ë°”ëŠ” í¬ê²Œ 3ê°€ì§€ ì…ë‹ˆë‹¤.</p>
<ul>
  <li>data augmentation ì¡°í•©ì´ SimCLR êµ¬ì¡°ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•œë‹¤.</li>
  <li>representationê³¼ contrasitve loss ì‚¬ì´ì˜ non-linear transformationì´ representation ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¨ë‹¤.</li>
  <li>contrastive learningì€ batch sizeì™€ training stepì´ í´ ë•Œ íš¨ê³¼ì ì´ë‹¤.</li>
</ul>

<p>ì´ë¯¸ì§€ì— ëŒ€í•œ representation learningì€ í¬ê²Œ generativeì™€ discriminativeë¡œ ë‚˜ëˆ ì§‘ë‹ˆë‹¤.
generative ì ‘ê·¼ë°©ì‹ì€ ë§ ê·¸ëŒ€ë¡œ ì´ë¯¸ì§€ë¥¼ reproducingí•˜ëŠ” ê³¼ì •ì—ì„œ ìœ ì˜ë¯¸í•œ representationì„ í•™ìŠµí•˜ëŠ” ë°©ì‹ì´ê³ ,
discriminativeëŠ” pretextë¥¼ ì •ì˜í•˜ê³  ì´ì— ë§ëŠ” objective functionì„ ì •ì˜í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.</p>

<p>ì´ ë…¼ë¬¸ì—ì„  discriminative ë°©ë²• ì¤‘ í•˜ë‚˜ì¸ contrastive learningì„ ì‚¬ìš©í•˜ì˜€ê³ , ë‹¤ì–‘í•œ ì‹¤í—˜ì„ í†µí•´ íš¨ìœ¨ì ìœ¼ë¡œ representationì„ í•™ìŠµí•  ìˆ˜ ìˆëŠ” êµ¬ì¡°ë¥¼ ì œì•ˆí•˜ê³  ìˆìŠµë‹ˆë‹¤.</p>

<h2 id="simclr--training">SimCLR &amp; Training</h2>
<p><img src="/assets/img/post2/algorithm.jpg" alt="algorithm" />
í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ê³¼ contrastive learningì€ ìœ„ ê·¸ë¦¼ìœ¼ë¡œ ëª¨ë‘ ì„¤ëª…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<ul>
  <li><img src="https://latex.codecogs.com/svg.latex?\; \tau" width="15" /> : ì‚¬ìš©ë  augmenationì˜ ì¢…ë¥˜</li>
  <li><img src="https://latex.codecogs.com/svg.latex?\; t, t^{'}" /> : <img src="https://latex.codecogs.com/svg.latex?\; \tau" width="15" />ì—ì„œ random samplingëœ augmentation</li>
  <li><img src="https://latex.codecogs.com/svg.latex?\; \widetilde{x}_i, \widetilde{x}_j" /> : augmenationëœ ì´ë¯¸ì§€</li>
  <li><img src="https://latex.codecogs.com/svg.latex?\; f(\cdot)" /> : resnet50 outputì—ì„œ global average poolingëœ ê°’</li>
  <li><img src="https://latex.codecogs.com/svg.latex?\; f(\cdot)" /> : resnet50 outputì—ì„œ global average poolingëœ ê°’</li>
</ul>

<p>ë‘ ì´ë¯¸ì§€ëŠ” fí•¨ìˆ˜ë¥¼ í†µê³¼í•˜ì—¬ hë¼ëŠ” representationìœ¼ë¡œ ì¸ì½”ë”©ë˜ê³  ì´ ê°’ì´ ì´ë¯¸ì§€ì˜ representationì´ ë˜ëŠ”ë°, fì—ëŠ” resnet50ì˜ outputì—ì„œ global average pooling ëœ ê°’ì´ ì‚¬ìš©ë©ë‹ˆë‹¤.
ì´ ë‹¤ìŒì— ì˜¤ëŠ” prejection head gê°€ contrastive lossì™€ representation ì‚¬ì´ì˜ non-linear transformationì´ ì ìš©ë˜ì—ˆë‹¤ê³  í•œ ë¶€ë¶„ì…ë‹ˆë‹¤.
ë‘ ì¸µì˜ MLPì™€ activation í•¨ìˆ˜ reluê°€ ì‚¬ìš©ë˜ê³  gì˜ ouputì¸ zë¡œ contrastive lossê°€ ê³„ì‚°ë˜ê²Œ ë©ë‹ˆë‹¤.</p>

<p>ê·¸ëŸ¼ loss ì‹ì˜ êµ¬ì„±ì„ í•˜ë‚˜ì”© ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.
similarity í•¨ìˆ˜ë¡œëŠ” cosine similarityê°€ ì‚¬ìš©ë˜ê³  ê°™ì€ ì´ë¯¸ì§€ì— ëŒ€í•œ ë‹¤ë¥¸ augmentationì€ positive sample, ë‹¤ë¥¸ ì´ë¯¸ì§€ì— ëŒ€í•œ augmentation ì´ë¯¸ì§€ëŠ” ëª¨ë‘ negative sampleë¡œ ë¶„ë¥˜í•˜ì—¬
positive sampleê³¼ì˜ similarityëŠ” ê°€ê¹ê²Œ, negative sampleê³¼ì˜ similarityëŠ” ë©€ê²Œ í•™ìŠµí•˜ê¸° ìœ„í•œ loss í•¨ìˆ˜ë¡œ ìƒê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ 
<img src="https://latex.codecogs.com/svg.latex?\; \tau" />ëŠ” temperature scalingì„ ìœ„í•œ parameterì…ë‹ˆë‹¤.</p>

<p>&lt;â€”â€”â€”â€”â€”â€”â€”- ì‘ì„±ì¤‘ â€”â€”â€”â€”â€”â€”â€”-&gt;</p>
<h2 id="reference">reference</h2>
<p>paper :<br />
SimCLR : <a href="https://arxiv.org/abs/2002.05709">https://arxiv.org/abs/2002.05709</a></p>

<p>etc :<br />
The Illustrated SimCLR Framework : <a href="https://amitness.com/2020/03/illustrated-simclr/">https://amitness.com/2020/03/illustrated-simclr/</a><br />
PR-231 : <a href="https://www.youtube.com/watch?v=FWhM3juUM6s&amp;t=1s">https://www.youtube.com/watch?v=FWhM3juUM6s&amp;t=1s</a></p>

:ET