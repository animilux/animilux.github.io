I"g<p>이 논문은 Geoffrey Hinton 교수님이 교신저자로 참여하신 논문인데요, 학습과정에서 augmentation과의 차이를 학습하는 것으로 image representation 성능을 크게 향상 시킨 논문입니다.</p>

<h2 id="intro">Intro</h2>
<p>이 논문에선 contrastive self-supervised learning을 제안하였는데, 이 구조는 복잡하지 않으며 별도의 memory bank가 필요하지 않다는 데에서 이전 연구들과 차이가 있습니다.
논문에서 입증한 바는 크게 3가지 입니다.</p>
<ul>
  <li>data augmentation 조합이 SimCLR 구조에서 중요한 역할을 한다.</li>
  <li>representation과 contrasitve loss 사이의 non-linear transformation이 representation 성능을 향상시킨다.</li>
  <li>contrastive learning은 batch size와 training step이 클 때 효과적이다.</li>
</ul>

<p>이미지에 대한 representation learning은 크게 generative와 discriminative로 나눠집니다.
generative 접근방식은 말 그대로 이미지를 reproducing하는 과정에서 유의미한 representation을 학습하는 방식이고,
discriminative는 pretext를 정의하고 이에 맞는 objective function을 정의하는 방식입니다.</p>

<p>이 논문에선 discriminative 방법 중 하나인 contrastive learning을 사용하였고, 다양한 실험을 통해 효율적으로 representation을 학습할 수 있는 구조를 제안하고 있습니다.</p>

<h2 id="simclr--training">SimCLR &amp; Training</h2>
<p><img src="/assets/img/post2/algorithm.jpg" alt="algorithm" />
학습 알고리즘과 contrastive learning은 위 그림으로 모두 설명할 수 있습니다.</p>
<ul>
  <li><img src="https://latex.codecogs.com/svg.latex?\; \tau" width="15" /> : 사용될 augmenation의 종류</li>
  <li><img src="https://latex.codecogs.com/svg.latex?\; t, t^{'}" /> : <img src="https://latex.codecogs.com/svg.latex?\; \tau" width="15" />에서 random sampling된 augmentation</li>
  <li><img src="https://latex.codecogs.com/svg.latex?\; \widetilde{x}_i, \widetilde{x}_j" /> : augmenation된 이미지</li>
  <li><img src="https://latex.codecogs.com/svg.latex?\; f(\cdot)" /> : resnet50 output에서 global average pooling된 값</li>
  <li><img src="https://latex.codecogs.com/svg.latex?\; f(\cdot)" /> : resnet50 output에서 global average pooling된 값</li>
</ul>

<p>두 이미지는 f함수를 통과하여 h라는 representation으로 인코딩되고 이 값이 이미지의 representation이 되는데, f에는 resnet50의 output에서 global average pooling 된 값이 사용됩니다.
이 다음에 오는 prejection head g가 contrastive loss와 representation 사이의 non-linear transformation이 적용되었다고 한 부분입니다.
두 층의 MLP와 activation 함수 relu가 사용되고 g의 ouput인 z로 contrastive loss가 계산되게 됩니다.</p>

<p>그럼 loss 식의 구성을 하나씩 살펴보겠습니다.
similarity 함수로는 cosine similarity가 사용되고 같은 이미지에 대한 다른 augmentation은 positive sample, 다른 이미지에 대한 augmentation 이미지는 모두 negative sample로 분류하여
positive sample과의 similarity는 가깝게, negative sample과의 similarity는 멀게 학습하기 위한 loss 함수로 생각할 수 있습니다. 여기서 
<img src="https://latex.codecogs.com/svg.latex?\; \tau" />는 temperature scaling을 위한 parameter입니다.</p>

<p>&lt;———————- 작성중 ———————-&gt;</p>
<h2 id="reference">reference</h2>
<p>paper :<br />
SimCLR : <a href="https://arxiv.org/abs/2002.05709">https://arxiv.org/abs/2002.05709</a></p>

<p>etc :<br />
The Illustrated SimCLR Framework : <a href="https://amitness.com/2020/03/illustrated-simclr/">https://amitness.com/2020/03/illustrated-simclr/</a><br />
PR-231 : <a href="https://www.youtube.com/watch?v=FWhM3juUM6s&amp;t=1s">https://www.youtube.com/watch?v=FWhM3juUM6s&amp;t=1s</a></p>

:ET