---
layout: post
title: "논문 리뷰 : Bootstrap Your Own Latent A New Approach to Self-Supervised Learning"
date: 2021-02-03 17:00:00 +0300
description: # Add post description (optional)
img: post5/byol_thumbs.jpg # Add image post (optional)
fig-caption: # Add figcaption (optional)
tags: [Unsupervised Learning, Representation Learning, Semi-Supervised Learning]
---
이번 논문은 Image Representation Learning에서 SimCLR과 MoCo의 성능을 모두 뛰어넘었다고 하는 BYOL 입니다. Google DeepMind와 Imperial College에서 발표하였고, 기존 연구들에 비해 Supervised Learning 성능(ResNet50, ImageNet acc 기준)에 가장 근접한 결과를 보여주고 있습니다. 

## Intro 
 Image representation learning 및 Unsupervised learning 분야에서 MoCo, SimCLR 등이 높은 성능을 보여주었지만, 이러한 선행 연구들에선 공통적으로, 적절한 augmentation의 사용과 학습 과정에서 많은 negative sample을 보는 것이 중요했습니다. 각 연구들에선 ImageNet data에 대해 실험을 통해 적절한 Augmentation과 batch size를 설정했지만, 이 값들은 data domain에 따라 달라질 수 있는 값들입니다. 즉, custom data에 적용할 경우, 대량의 Unlabeled data와 소량의 Labeled data를 사용한 Semi-Supervised Learning을 적용한다고 생각하면, 적절한 Augmentation 선정과 사용가능한 resource 내에서 batch size의 설정 등이 많은 실험을 필요로 할 것입니다.   

 이 논문에선 이전 연구들에 비해 batch size와 augmentation에 대한 robustness를 증가시키면서, Image representation learning 성능도 개선된 결과를 보여줍니다. 특히, 학습 과정에서 negative sample을 전혀 사용하지 않았다는 점이 이전 연구와는 가장 큰 차이라고 할 수 있습니다. 두 개의 neural network을 사용하고 이 중 하나를 target network로 사용하는 것이 핵심 아이디어 입니다.

## Methods
논문의 motivation은 간단한 실험에서 출발합니다. 

![motive]({{site.baseurl}}/assets/img/post5/motive.jpg)

* step1 : randomly initialized network를 freeze하고 linear evaluation을 진행합니다.  
-> Acc 1.4%
* step2 : step1의 network에 MLP를 붙여 prediction 값을 얻습니다.
* step3 : step2에서 얻은 prediction 값을 target으로 하여 step1처럼 randomly initialized network를 학습하고 linear evaluation을 진행합니다.   
-> Acc 18.8%

"동일 instance에 대해 다른 augmentation을 적용한 이미지는 representation이 동일해야 한다." 가 instance discrimination 방식인 contrastive learning의 기본 아이디어 였는데요. 이 아이디어만으로 학습 framework을 구성할 시, 모델은 input과 무관하게 동일 representation을 출력하도록 학습될 수 있고 이를 논문에서는 'collapsed representations'이라고 말합니다. 이 문제가 이전 연구들에서 negative sample을 사용해야만 했던 이유라고 할 수 있습니다.

여기서, 학습을 시작하기전 randomly initialized network에서 얻은 representation을 생각해보면 이미지의 특성을 잘 반영한 representation은 아니겠지만, 아직 학습을 시작하지 않았기에 collapsed 문제는 없을 것으로 생각할 수 있습니다. 이렇게 얻은 representation의 성능이 step1에서 구한 1.4%였습니다. ImageNet 데이터가 1000개의 class임을 감안하면 학습한 1개의 linear layer에서 어느정도의 학습은 이루어진 것으로 보입니다.

step2~3의 결과는 step1에서 얻은 의미없는(randomly initilized 이므로) representation을 target으로 학습하는 것도 어느 정도의 의미는 있다는 것을 보여줍니다. 이 부분이 개인적으로 좀 신기한 부분이었는데요. 틀린 답으로 학습하는 것도 전혀 학습하지 않은 것보다는 도움이 된다고 해석할 수 있기 때문입니다.

논문에선 위 실험결과를 시작으로 representation을 학습할 online network와 학습하는 prediction을 출력할 target network를 아래와 같이 설계하게 됩니다.

![byol_thumbs]({{site.baseurl}}/assets/img/post5/byol_thumbs.jpg)





## Results

## Conclusion


<----- 작성중 ----->



## Reference 
paper :  
<a href="https://arxiv.org/abs/2006.07733​">Bootstrap Your Own Latent A New Approach to Self-Supervised Learning</a>

etc :   
<a href="https://hoya012.github.io/blog/byol/">HOYA012'S RESEARCH BLOG : Bootstrap Your Own Latent： A New Approach to Self-Supervised Learning 리뷰</a>  
<a href="https://2-chae.github.io/category/2.papers/26">https://2-chae.github.io/category/2.papers/26</a>  
<a href="https://cool24151.tistory.com/85">https://cool24151.tistory.com/85</a> 
<a href="https://www.youtube.com/watch?v=BuyWUSPJicM">딥러닝논문읽기모임 : 조용민 - Bootstrap Your Own Latent(BYOL)</a> 
  







